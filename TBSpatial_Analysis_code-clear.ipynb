{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc19833a",
   "metadata": {},
   "source": [
    "### Quantify image-based metrics of TB stain with single-cell segmentation geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e002fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import anndata as ad\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.affinity import translate\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n",
    "import scanpy as sc\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83289b62-c9e6-4659-b8e9-812aa06f0b2b",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "After downloading the entire data folder, unzip the .tgz files with the command tar -xzvf filename.tgz. You should end up with a folder containing the following subfolders: \n",
    "\n",
    "vizgen_files.tgz contains the .vzg files for each section. These files are not used in this script but are instead provided in case anyone wants to load the files into the Merfish Vizualizer. \n",
    "\n",
    "*Folder Names*\n",
    "\n",
    "TBSpatial_Analysis_LCD_112023.ipynb #Code used to create spatial analysis graphs in this publication \\\n",
    "figures #all the figures printed in this script \\\n",
    "Stats #all the statistics calculated in this script \\\n",
    "Annotated_h5ad #merged H5AD files from spatial analysis and Smartseq2 sequencing \\\n",
    "Annotated_h5ad_individual #Annotated H5AD files for each spatial section \\\n",
    "cell_annotations #csv files with cell annotations to load into the Merfish Vizualizer \\\n",
    "postprocessed_counts #counts generated by Merscope post-processing \\\n",
    "202305231432_TB-CTRL1-MB_VMSC02401 \\\n",
    "202305251147_TB-CTRL2-MB_VMSC02401 \\\n",
    "202305261458_TB-TEST3-MB_VMSC02401 \\\n",
    "202309251210_20230925-RitwicqA-TB_VMSC02401 \\\n",
    "202310091253_AmandaS-TB-02_VMSC02401 \\\n",
    "202310111428_RitwicqA-TB-4b_VMSC02401 \\\n",
    "avg_signal_df.csv #csv file with all the TB antibody staining values per cell\n",
    "\n",
    "\n",
    "If you run this code from within its code folder, you should not need to edit anything in order to get it to run. \n",
    "\n",
    "The first chunk of code (below the functions; \"Run all the code on each section\") takes a lot of time and generates files that are already present, so you can skip it and run the next piece of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f2de9-efc5-4469-ab04-3bee4a22917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = !pwd\n",
    "dataPath = dataPath[0]+'/'\n",
    "processedDataPath = dataPath+'postprocessed_counts/'\n",
    "\n",
    "threshold = 300\n",
    "std_threshold = 150 \n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "binsize=100\n",
    "perm_iterations=10000\n",
    "pval_threshold = 0.001\n",
    "stat_threshold = 0.15\n",
    "\n",
    "marker_dict = {'High':['Nos2', 'H2Ab1', 'Irf1','C1qb'], 'Low':['Sparc','Jun','Lyve1'],'Neither':['Irf9','H2K1','Cxcr2']}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da4c4635-2089-4936-b216-86fde92e9f6d",
   "metadata": {},
   "source": [
    "Extra information:\n",
    "Panel: https://docs.google.com/spreadsheets/d/1RS2xFdSDkf78g5Sd5VZyuJSCvmJ6rur6fHlNgilKsgY/edit#gid=287597825\n",
    "\n",
    "Dendritic Cell top genes: ['Ccr7', 'Ccl22', 'Ly6d', 'Nr4a3', 'Xcr1', 'Dpp4', 'Irf4', 'Cd83']\n",
    "Neutrophil top genes: ['Cxcr2', 'Csf3r', 'Il1r2']\n",
    "Alveolar Macrophage top genes: ['Krt79', 'Plet1', 'Cd2', 'Car4', 'Mrc1', 'Marco', 'Tgfb2', 'Siglec1', 'Pparg']\n",
    "moDerived Macrophage top genes: ['Nos2', 'C1qc', 'C1qa', 'C1qb', 'Ms4a7', 'Sod2', 'Socs1', 'Cd40', 'Clec4e’,’Fcgr1’ ,’Ly6c2’]\n",
    "Immature_moDerived Macrophage top genes: ['Nr4a1', 'Plac8', 'Cx3cr1', 'Sell', 'Spn', 'F13a1', 'Ccl9', 'Ly6c2']\n",
    "MTB-high: ['Dnase1l3']\n",
    "\n",
    "X_spatial and center_x, center_y are in micron units\n",
    "set binsize to 100 for 100 um\n",
    "\n",
    "Thresholds: \n",
    "    minimum top average: 300\n",
    "    minimum st dev: 150\n",
    "    remove cells >400 um from 2nd closest TB+ neighbor\n",
    "    remove cells with >5 million cellbound 3 high pass\n",
    "    \n",
    "Extra thresholds: \n",
    "    Test3: Cut off left 2000 microns, exclude anything with center_x > 4000\n",
    "    202309251210_20230925-RitwicqA-TB_VMSC02401 region 1: Cut off left 7500 microns, bottom >6500 microns\n",
    "    202309251210_20230925-RitwicqA-TB_VMSC02401 region 2: Cut off left 2500 microns, **Min top avg = 250**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa601cb6-7bb6-413b-8a61-78fe7086551f",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb2eab-5871-4aa5-9c29-868051d2a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_h5ad_folder(input_folder,\n",
    "                            output_folder='None',\n",
    "                            name = 'concatenated_10x_output',\n",
    "                            regex = ['donor','tissue','anatomical_position','method','sample','replicate','notes'],\n",
    "                            regex_sep = '_',\n",
    "                            counts_threshold=1000,\n",
    "                            genes_threshold=100,\n",
    "                            adata_file = 'None',\n",
    "                            save_frequency = 100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take output files from decontx processing and concatenate into anndata object\n",
    "    \"\"\"\n",
    "    \n",
    "    if output_folder=='None':\n",
    "        output_folder=input_folder\n",
    "    \n",
    "    if not os.path.isdir(input_folder):\n",
    "        raise SyntaxError('Input folder cannot be found')   \n",
    "        \n",
    "    if not os.path.isdir(output_folder):\n",
    "        raise SyntaxError('output folder cannot be found')   \n",
    "    \n",
    "    adata = sc.AnnData()\n",
    "        \n",
    "    files = [i for i in os.listdir(input_folder) if i.endswith(('.h5ad','.h5ad.gz'))]\n",
    "    print(\"first file: \",files[0])\n",
    "    count = 0\n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        \n",
    "        info = file.split(\".\")[0] #assuming information is present in the filename\n",
    "        if not file.startswith('2023'):\n",
    "            continue\n",
    "        #add something to check whether a given sample is already present in the adata file\n",
    "        if adata_file!='None':\n",
    "            if info in list(adata.obs['10X_run']):\n",
    "                print('The sample ', info,' is already in the object. Skipping.')\n",
    "                continue\n",
    "        info_split = info.split(regex_sep)\n",
    "        if len(info_split)<len(regex):\n",
    "            print('Warning: the sample ',info,' does not have enough metadata information, ',regex[len(info_split):],' will be excluded')\n",
    "            regex_fix = regex[:len(info_split)]\n",
    "        else:\n",
    "            regex_fix = regex\n",
    "            \n",
    "            \n",
    "        print('reading ',file)\n",
    "        adata_interim = sc.read_h5ad(os.path.join(input_folder,file))\n",
    "        \n",
    "        #add in .obs - this depends on the actual metadata format\n",
    "        print('adding .obs columns to anndata object')\n",
    "        \n",
    "        adata_interim.obs['full_sample'] = info\n",
    "           \n",
    "        for n in range(0,len(regex_fix)):\n",
    "            adata_interim.obs[regex_fix[n]] = info.split(regex_sep)[n]\n",
    "        \n",
    "        adata_interim.obs['cell_id'] = adata_interim.obs['full_sample'] + \"_\" + adata_interim.obs.index.astype('str')\n",
    "        adata_interim.obs.set_index('cell_id',inplace=True)\n",
    "        \n",
    "        try:\n",
    "            del adata_interim.obsm\n",
    "        except:\n",
    "            adata_interim\n",
    "        \n",
    "        for obs_column in adata.obs.columns:\n",
    "            if \".\" in obs_column:\n",
    "                adata.obs[obs_column] = adata.obs[obs_column].astype('str')\n",
    "            \n",
    "        if adata.shape[0]>1:  \n",
    "            adata = ad.concat([adata,adata_interim],join='outer',merge='unique')\n",
    "            print('added to adata')\n",
    "        else:\n",
    "            adata = adata_interim.copy()\n",
    "            print('copying interim')\n",
    "            \n",
    "        adata.obs = adata.obs.astype('str')\n",
    "        count = count+1\n",
    "        \n",
    "        if count == save_frequency:\n",
    "            adata.write_h5ad(os.path.join(output_folder,name+'.h5ad'))\n",
    "            count=0\n",
    "        \n",
    "        gc.collect()\n",
    "            \n",
    "    \n",
    "    adata.write_h5ad(os.path.join(output_folder,name+'.h5ad'))\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e267a19-f7d3-4d0c-ae86-defef800c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def load_image_roi(file_name, window_coords):\n",
    "    try:\n",
    "        with rio.open(file_name) as aws_file:\n",
    "            roi = aws_file.read(1, window=rio.windows.Window(*window_coords))\n",
    "    except OSError:\n",
    "        print(f\"File read error on {file_name}\")\n",
    "        roi = np.zeros([window_coords[3],window_coords[2]])\n",
    "        \n",
    "    return np.squeeze(roi)\n",
    "\n",
    "def convert_eight_bit(img):\n",
    "    # Normalize contrast before reducing bit depth\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    norm_img = clahe.apply(img)    \n",
    "    bg_subtract = norm_img - norm_img.min()\n",
    "    \n",
    "    if bg_subtract.max() == 0:\n",
    "        return np.zeros(img.shape, dtype=np.uint8)\n",
    "    else:\n",
    "        range_norm = bg_subtract / bg_subtract.max()      \n",
    "        return np.array(range_norm * 255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710fc6e-4dd8-439f-ba6d-4e27c7e02c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tb_image_information(dataPath, experimentName, region):\n",
    "    \n",
    "    #initialize a dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    #iterate through the z planes - in this case there are 7\n",
    "    for z in range(0,7):\n",
    "        z_level = str(z)\n",
    "        print('z_level: ', z_level)\n",
    "    \n",
    "        # Segmentation boundaries\n",
    "        geometries = gpd.read_parquet(\n",
    "            os.path.join(dataPath, experimentName, 'region_' + region, 'cell_boundaries.parquet')).set_index('EntityID')\n",
    "    #print('Segmentation geometries loaded.')\n",
    "\n",
    "    # TB stain channel image, AKA cellbound3\n",
    "        TBmosaicPath = os.path.join(\n",
    "            dataPath, experimentName, 'region_' + region, 'images', 'mosaic_Cellbound3_z' + z_level + '_lzw.tif')\n",
    "\n",
    "    # DAPI stain channel image\n",
    "        #DAPImosaicPath = os.path.join(\n",
    "        #    dataPath, experimentName, 'region_' + region, 'images', 'mosaic_DAPI_z' + z_level + '.tif')\n",
    "    \n",
    "\n",
    "    #print('Mosaic filepaths loaded.')\n",
    "\n",
    "    # Micron to mosaic pixel transform\n",
    "        transformationMatrix = np.loadtxt(\n",
    "            os.path.join(dataPath, experimentName, 'region_' + region, 'images', 'micron_to_mosaic_pixel_transform.csv'))\n",
    "    \n",
    "    # Convert transformation matrix to correct affine transformation format for Geopandas\n",
    "        t = transformationMatrix\n",
    "        affine_matrix = [t[0,0], t[0,1], t[1,0], t[1,1], t[0,2], t[1,2]]\n",
    "\n",
    "    #print('Micron to mosaic pixel transform loaded.')\n",
    "\n",
    "    # Create new geodataframe column with mosaic pixel units\n",
    "        geometries_mosaic = geometries.copy()\n",
    "        geometries_mosaic['Geometry'] = geometries['Geometry'].affine_transform(affine_matrix)\n",
    "\n",
    "    #print('Mosaic geometries calculated.')\n",
    "\n",
    "    # Check that we have the right coordinates by overlaying with DAPI channel\n",
    "    # What are the dimensions of the overall experiment?\n",
    "        #s = rio.open(DAPImosaicPath)\n",
    "        #print('Dimensions of experiment are ' + str(s.width) + ' x ' + str(s.height) + ' in pixels.')\n",
    "\n",
    "        gdf = geometries_mosaic.copy()\n",
    "        gdf = gdf[gdf['ZIndex'] == int(z_level)]\n",
    "\n",
    "        shapes = list(gdf['Geometry'])\n",
    "        masks = []\n",
    "\n",
    "        with rio.open(TBmosaicPath) as src:\n",
    "            for shape in tqdm(shapes):\n",
    "                out_image, _ = mask(src, shape.geoms, crop=True)\n",
    "                masks.append(out_image)\n",
    "        \n",
    "    # Save array of pixel intensities for each cell\n",
    "        gdf['TB_intensities'] = pd.Series(dtype='object')\n",
    "    #for i in tqdm(range(len(gdf))):\n",
    "        #gdf.loc[:,'TB_intensities'].loc[gdf.index[i]] = masks[i][np.nonzero(masks[i])]\n",
    "    \n",
    "    \n",
    "    #all nonzero TB intensities for each cell\n",
    "        gdf['TB_intensities'] = [masks[i][np.nonzero(masks[i])] for i in range(len(gdf))] \n",
    "    \n",
    "    #all TB intensities for each cell, including zeros\n",
    "        gdf['TB_spatial'] = [masks[i].squeeze() for i in range(len(gdf))] \n",
    "\n",
    "    # Calculate some metrics\n",
    "\n",
    "    # Sum signal\n",
    "        gdf['sum_signal'] = [gdf.iloc[i]['TB_intensities'].sum() for i in range(len(gdf))]\n",
    "\n",
    "    # Mean (excluding zeros)\n",
    "        gdf['mean_signal'] = [gdf.iloc[i]['TB_intensities'].mean() for i in range(len(gdf))]\n",
    "    \n",
    "    # Median (excluding zeros)\n",
    "        gdf['median_signal'] = [np.median(gdf.iloc[i]['TB_intensities']) for i in range(len(gdf))]\n",
    "    \n",
    "    # Standard deviation (excluding zeros)\n",
    "        gdf['std_signal'] = [gdf.iloc[i]['TB_intensities'].std() for i in range(len(gdf))]\n",
    "\n",
    "    # Average of top 100 values\n",
    "        gdf['top_avg_signal'] = [np.sort(gdf.iloc[i]['TB_spatial'])[::-1][:100].mean() for i in range(len(gdf))]\n",
    "\n",
    "    #create a data frame we can add to for each z plane:\n",
    "        add = gdf[['ZIndex','sum_signal','mean_signal','median_signal','std_signal','top_avg_signal']]\n",
    "        df = pd.concat([df,add])\n",
    "    return df\n",
    "    \n",
    "def make_average_gdf(df,adata):\n",
    "\n",
    "#find the mean values for each entity across z positions\n",
    "#add a binary classifier to adata\n",
    "    avg_signal_df = pd.DataFrame(columns=df.columns)\n",
    "    for ind in tqdm(list(set(df.index))):\n",
    "        sub = df.loc[ind]\n",
    "        avg = sub.mean(axis=0)\n",
    "        avg_signal_df.loc[ind] = avg\n",
    "\n",
    "    avg_signal_df.index = [str(i) for i in avg_signal_df.index]\n",
    "\n",
    "    #subset to only cells that are included in the final object\n",
    "    avg_signal_df['Entity_ID'] = avg_signal_df.index.astype('str').copy()\n",
    "    avg_signal_df = avg_signal_df[avg_signal_df.Entity_ID.isin(list(adata.obs.index))].copy()\n",
    "    avg_signal_df.set_index('Entity_ID',inplace=True)\n",
    "    print(avg_signal_df.shape)\n",
    "\n",
    "    return avg_signal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956fd07-eedf-4e11-8878-9067962dcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vizgen_h5ad(processedDataPath,experimentName, filename, region,\n",
    "                    min_volume=200, max_volume=5000, min_counts=20, min_dapi = 2000000, TB_threshold = 700000):\n",
    "    \n",
    "    #read in the h5ad file\n",
    "    adata = sc.read_h5ad(processedDataPath+experimentName+'/'+filename)\n",
    "\n",
    "    #print the number of cells, cells per region, and show the object\n",
    "    print('number of cells in unfiltered dataset: ',adata.shape[0])\n",
    "    print('cells per region: ', adata.obs.region.value_counts())\n",
    "\n",
    "    #filter to one region at a time\n",
    "    adata = adata[adata.obs.region==region].copy()\n",
    "    adata\n",
    "\n",
    "    # Calculate total counts\n",
    "    adata.obs['total_counts'] = adata.X.toarray().sum(axis=1)\n",
    "    adata.obs['log_total_counts'] = np.log(adata.obs['total_counts'] + 1)\n",
    "    \n",
    "    #print graphs\n",
    "    #Create thresholds based on the plots above, and plot those lines onto the data. \n",
    "    fig, axes = plt.subplots(1,4, figsize=(12,4))\n",
    "\n",
    "    # Cell volume\n",
    "    bins = np.logspace(0,4,20)\n",
    "    ax = axes[0]\n",
    "    ax.hist(adata.obs['volume'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('cell volume (um^3)')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xscale('log')\n",
    "    ax.axvline(min_volume,color='red')\n",
    "    ax.axvline(max_volume,color='black')\n",
    "    ax.axhline(0.05,color='red')\n",
    "\n",
    "    # Total transcripts per cell\n",
    "    bins = np.logspace(0,3.5,20)\n",
    "    ax = axes[1]\n",
    "    ax.hist(adata.obs['total_counts'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('total transcripts')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xscale('log')\n",
    "    ax.axvline(min_counts,color='red')\n",
    "    ax.axhline(0.20,color='red')\n",
    "\n",
    "\n",
    "    # DAPI signal per cell\n",
    "    bins = np.logspace(2,8,20)\n",
    "    ax = axes[2]\n",
    "    ax.hist(adata.obs['DAPI_high_pass'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('DAPI')\n",
    "    ax.set_ylabel('fraction of cells')\n",
    "    ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "    ax.axvline(min_dapi,color='red')\n",
    "    ax.axhline(0.1,color='red')\n",
    "\n",
    "    # TB signal per cell\n",
    "    bins = np.logspace(2,6,20)\n",
    "    ax = axes[3]\n",
    "    ax.hist(adata.obs['Cellbound3_high_pass'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('TB stain')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xscale('log')\n",
    "    ax.axhline(0.95,color='black')\n",
    "    ax.axvline(TB_threshold,color='black')\n",
    "\n",
    "    print('saving figure')\n",
    "    fig.savefig(dataPath+'figures/'+experimentName+'region'+str(region)+'_basicQC.pdf')\n",
    "    print(\"size of adata object: \", adata.shape)\n",
    "    return adata\n",
    "\n",
    "def filter_h5ad(adata,min_volume=200, max_volume=5000, min_counts=20, min_dapi = 2000000):\n",
    "    #filter the object based on the thresholds above\n",
    "    cells = adata.shape[0]\n",
    "    adata = adata[(adata.obs['volume'] > min_volume) &\n",
    "         (adata.obs['volume'] < max_volume) &\n",
    "         (adata.obs['total_counts'] > min_counts) &\n",
    "         (adata.obs['DAPI_high_pass'] > min_dapi)].copy()\n",
    "    print('Filtering complete: ' + str(len(adata)) + ' cells remaining out of ' + str(cells) + ' original cells.')\n",
    "    return adata\n",
    "\n",
    "def show_spatial_plots(adata, clipx, experimentName, region,figsize = (10,10)):\n",
    "    #Show the section and add lines for any removal of damage\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sc.pl.spatial(adata, color='Cellbound3_high_pass', spot_size=50, ax=ax,color_map='OrRd',vmax=5000000)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axvline(clipx,color='red')\n",
    "    ax.axvline(clipx+1000,color='blue')\n",
    "\n",
    "    if experimentName == '202309251210_20230925-RitwicqA-TB_VMSC02401' and region=='1':\n",
    "        ax.axhline(6500,color='red')\n",
    "        ax.axhline(7500,color='blue')\n",
    "    sc.pl.spatial(adata, color='log_total_counts', spot_size=30, ax=ax)\n",
    "    \n",
    "def sc_preprocess(adata):\n",
    "    # Basic scanpy preprocessing\n",
    "    adata.X = adata.layers['counts'].copy()\n",
    "    sc.pp.normalize_total(adata,target_sum=100)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    #save normalized data\n",
    "    adata.layers['log_normalized'] = adata.X.copy()\n",
    "    print('log normalized')\n",
    "\n",
    "    #scale data\n",
    "    sc.pp.scale(adata)\n",
    "    adata.layers['scale_data'] = adata.X.copy()\n",
    "    print('scaled')\n",
    "\n",
    "    #run dimensional reduction\n",
    "    print('calculating pcs')\n",
    "    sc.pp.pca(adata)\n",
    "\n",
    "    print('calculating umap')\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    sc.tl.leiden(adata, resolution=0.5)\n",
    "\n",
    "    print('Scanpy processing complete.')\n",
    "    #check that counts remain\n",
    "    print(adata.layers['counts'][:1,:5])\n",
    "    return adata\n",
    "\n",
    "def tbcells_only_calculate_distance_to_tb(adata):\n",
    "    adata.obs['distance_to_tb'] = -100\n",
    "    #calculate euclidean distance from each of these cells to every other cell, find the minimum\n",
    "    tb_cells = adata.obs.index[adata.obs.TB_class_from_images=='High']\n",
    "    \n",
    "    #iterate over all tb cells\n",
    "    #find the location of the cell in space\n",
    "    #X_spatial is not an x-coordinate, it's a point\n",
    "    \n",
    "    for cell in tqdm(list(tb_cells)):\n",
    "        dist = []\n",
    "        cell_loc = np.round(list([adata.obs.center_x[cell],adata.obs.center_y[cell]]),decimals=2)\n",
    "    \n",
    "        #iterate over all TB+ cells and find the distance from each one to the cell in question\n",
    "        for tb_cell in tb_cells:\n",
    "            tb_cell_loc = np.round(list([adata.obs.center_x[tb_cell],adata.obs.center_y[tb_cell]]),decimals=2)\n",
    "            new_dist = np.round(math.dist(cell_loc,tb_cell_loc),decimals=2)\n",
    "            dist.append(new_dist)\n",
    "\n",
    "        #find the minimum distance to the 2nd tb+ cell\n",
    "        try:\n",
    "            min_dist = sorted(dist,reverse=False)[2]\n",
    "        except:\n",
    "            min_dist = 401\n",
    "            print('not enough cells to calculate min distance')\n",
    "        \n",
    "        #add this to the object\n",
    "        adata.obs.loc[cell,'distance_to_tb'] = min_dist\n",
    "        \n",
    "    #show any outliers in terms of cellbound 3 (tb) or distance to tb, print a graph\n",
    "    print(\"cells with TB signal above 5 million:\", adata[adata.obs.Cellbound3_high_pass>5e6].shape[0])\n",
    "    sc.pl.scatter(adata[adata.obs.TB_class_from_images=='High'],x='center_x',y='distance_to_tb',color='Cellbound3_high_pass')\n",
    "    \n",
    "    return adata\n",
    "\n",
    "#calculate euclidean distance from each of the tb+ cells to every other cell, find the minimum\n",
    "def calculate_distance_to_tb(adata):\n",
    "    if 'High' in set(adata.obs.TB_class_from_images):\n",
    "\n",
    "        adata.obs['distance_to_tb'] = -100\n",
    "\n",
    "\n",
    "        tb_cells = adata.obs.index[adata.obs.TB_class_from_images=='High']\n",
    "        count=1\n",
    "    #iterate over all cells\n",
    "        for cell in tqdm(list(adata.obs.index)):\n",
    "            dist = []\n",
    "    \n",
    "        #if the cell is TB+, distance = 0\n",
    "            if adata.obs.loc[cell,'TB_class_from_images']=='High':\n",
    "                adata.obs.loc[cell,'distance_to_tb'] = 0\n",
    "                continue\n",
    "        \n",
    "            cell_loc = np.round(list([adata.obs.center_x[cell],adata.obs.center_y[cell]]),decimals=2)\n",
    "    #if the cell is not TB+, calculate its distance from each TB+ cell\n",
    "    #iterate over all TB+ cells and find the distance from each one to the cell in question\n",
    "            for tb_cell in tb_cells:\n",
    "                tb_cell_loc = np.round(list([adata.obs.center_x[tb_cell],adata.obs.center_y[tb_cell]]),decimals=2)\n",
    "                new_dist = np.round(math.dist(cell_loc,tb_cell_loc),decimals=2)\n",
    "                dist.append(new_dist)\n",
    "\n",
    "    #find the minimum distance\n",
    "            min_dist = min(dist)\n",
    "    \n",
    "    #add this to the object\n",
    "            adata.obs.loc[cell,'distance_to_tb'] = min_dist\n",
    "    else:\n",
    "        adata.obs['distance_to_tb'] = 5000\n",
    "    return adata\n",
    "\n",
    "#run a permutation test comparing each transcript from within the binsize relative to a tb+ cell against all cells\n",
    "def permutation_test_for_tb_loc(adata,layer='log_normalized',binsize=100,perm_iterations=1000):\n",
    "\n",
    "    if isinstance(adata.layers[layer], scipy.sparse._csr.csr_matrix):\n",
    "        adata_df = pd.DataFrame.sparse.from_spmatrix(adata.layers[layer])\n",
    "        adata_df = adata_df.sparse.to_dense()\n",
    "    else:\n",
    "        adata_df = pd.DataFrame(adata.layers[layer])\n",
    "    adata_df.columns = adata.var.index\n",
    "    adata_df.index = adata.obs.index\n",
    "    adata_df['distance_real'] = adata.obs['distance_to_tb'].copy()\n",
    "    adata_df.columns = [i.replace('-','') for i in adata_df.columns]\n",
    "\n",
    "    adata_df['Bin'] = 'Null'\n",
    "\n",
    "    #for the first 4 bins, plot the distribution on top of this one in a different color\n",
    "    adata_df.loc[(adata_df.distance_real>=6*binsize) & (adata_df.distance_real<7*binsize),'Bin'] = 'Bin7'\n",
    "    adata_df.loc[(adata_df.distance_real>=3*binsize) & (adata_df.distance_real<4*binsize),'Bin'] = 'Bin4'\n",
    "    adata_df.loc[(adata_df.distance_real>=2*binsize) & (adata_df.distance_real<3*binsize),'Bin'] = 'Bin3'\n",
    "    adata_df.loc[(adata_df.distance_real>=binsize) & (adata_df.distance_real<2*binsize),'Bin'] = 'Bin2'\n",
    "    adata_df.loc[adata_df.distance_real<binsize,'Bin'] = 'Bin1'\n",
    "    adata_df.loc[adata_df.distance_real==0,'Bin'] = 'Bin0'\n",
    "    print(\"number of cells per bin: \",adata_df.Bin.value_counts())\n",
    "    adata_df = adata_df.sort_values('Bin',ascending=True)\n",
    "\n",
    "    #permutation test ~43 iterations/second\n",
    "    df_results = pd.DataFrame(columns=['sample_stat','average_stat','p_value'])\n",
    "    for transcript in tqdm(adata_df.columns[:140]):\n",
    "        #calculate a \"null distribution\" excluding TB+ and nearby cells\n",
    "        ref_average = np.mean(adata_df.loc[~adata_df['Bin'].isin(['Bin1','Bin0']),transcript])\n",
    "        #print(ref_average)\n",
    "                              \n",
    "        sample_stat = np.mean(adata_df.loc[adata_df['Bin']=='Bin1',transcript]) - ref_average #calculate the difference in means between your bin1 distribution and the null distribution\n",
    "        stats = np.zeros(perm_iterations)\n",
    "        for k in range(perm_iterations):\n",
    "            labels = np.random.permutation((adata_df['Bin'] == 'Bin1').values) #randomly rearrange the bin labels so you get another sample in 'Bin1'\n",
    "            stats[k] = np.mean(adata_df[transcript][labels]) - ref_average #for each of 1000 iterations, calculate the difference between the random Bin1 Nos2 values and the null distribution\n",
    "    \n",
    "        if sample_stat>=0:\n",
    "            p_value = np.mean(stats > sample_stat)\n",
    "        if sample_stat<0:\n",
    "            p_value = np.mean(stats < sample_stat)\n",
    "    #save the stat and p-value per transcript\n",
    "        df_results.loc[transcript] = [sample_stat,np.mean(stats),p_value] \n",
    "\n",
    "    df_results = df_results.sort_values('p_value',ascending=True)\n",
    "    return adata_df, df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aff1b7-df90-483c-b017-d83c03bb3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations):\n",
    "    top_hits = df_results[(df_results.p_value<pval_threshold)].sort_values('sample_stat',ascending=False)\n",
    "    top_hits = list(top_hits[top_hits.sample_stat>stat_threshold].index)\n",
    "    top_hits = [i for i in top_hits if not i.startswith('Blank')]\n",
    "\n",
    "    bottom_hits =df_results[(df_results.p_value<pval_threshold) & (df_results.sample_stat< -stat_threshold)].index\n",
    "    bottom_hits = [i for i in bottom_hits if not i.startswith('Blank')]\n",
    "\n",
    "    #show violin or feature plots of these genes in the smartseq data\n",
    "   \n",
    "    if len(top_hits)>2:\n",
    "        sc.pl.heatmap(sc_data,top_hits,groupby='leiden',show_gene_labels=True)\n",
    "        #sc.pl.stacked_violin(sc_data,top_hits,groupby='leiden',rotation=90,title = 'Upregulated near TB')\n",
    "    if len(bottom_hits)>2:\n",
    "        sc.pl.heatmap(sc_data,bottom_hits,groupby='leiden',show_gene_labels=True)\n",
    "        #sc.pl.stacked_violin(sc_data,bottom_hits,groupby='leiden',rotation=90,title='Downregulated near TB')\n",
    "    \n",
    "    allprobes = [i for i in list(df_results.index) if not i.startswith('Blank')]\n",
    "\n",
    "    sc_data.var['UpNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(top_hits),'UpNearTB'] = True\n",
    "\n",
    "    sc_data.var['DownNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(bottom_hits),'DownNearTB'] = True\n",
    "\n",
    "    sc_data.var['UnchangedNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(allprobes),'UnchangedNearTB'] = True\n",
    "    sc_data.var.loc[sc_data.var['UpNearTB']==True,'UnchangedNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var['DownNearTB']==True,'UnchangedNearTB'] = False\n",
    "\n",
    "    print(\"up near TB: \", len(top_hits), \"\\ndown near TB:\", len(bottom_hits))\n",
    "\n",
    "    sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','UnchangedNearTB'],inplace=True)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    #sc.pl.violin(sc_data,['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'],groupby='leiden',rotation=90)\n",
    "    sc.pl.violin(sc_data,['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experimentName+'region'+str(region)+'ViolinPlot_UP_TB.pdf',ax=ax)\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experimentName+'region'+str(region)+experimentName+'region'+str(region)+'ViolinPlot_Down_TB.pdf',ax=ax)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_UnchangedNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experimentName+'region'+str(region)+'ViolinPlot_NOCHANGE_TB.pdf',ax=ax)\n",
    "\n",
    "    print(df_results.p_value[df_results.p_value>0].min())\n",
    "    df_results.loc[df_results.p_value==0,'p_value'] = 0.9/perm_iterations\n",
    "    df_results.to_csv(dataPath+'Stats/stats'+experimentName+'_region'+str(region)+'.csv')\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(x = df_results.sample_stat, y=-np.log10(df_results.p_value))\n",
    "    plt.xlabel('difference in means, Bin1 - Null')\n",
    "    plt.ylabel('-log p value')\n",
    "\n",
    "    for i in range(df_results.shape[0]):\n",
    "        plt.text(x=df_results.sample_stat[i],y=-np.log10(df_results.p_value[i]),s=df_results.index[i], \n",
    "              fontdict=dict(color='black',size=10))\n",
    "    \n",
    "    plt.savefig(dataPath+'figures/volcano'+experimentName+'_region'+str(region)+'.pdf')\n",
    "    return sc_data\n",
    "\n",
    "def plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax = 0):\n",
    "#run for each set of marker genes\n",
    "    for celltype in list(marker_dict.keys()):\n",
    "   \n",
    "        for transcript in marker_dict[celltype]:\n",
    "            if ymax==0:\n",
    "                ymax_new = max(adata_df[transcript])\n",
    "            else:\n",
    "                ymax_new=ymax\n",
    "    #if transcript not in ['Nos2','C1qa','C1qb','C1qc','Fcgr4','Lyve1']:\n",
    "        #continue\n",
    "  \n",
    "            fig,ax = plt.subplots(figsize=(5,3))\n",
    "            sns.histplot(data = adata_df,\n",
    "                 x=transcript, \n",
    "                 bins=10000, \n",
    "                 binrange=(0,ymax_new),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True,\n",
    "                color='Grey',\n",
    "                alpha=0.5)\n",
    "        \n",
    "    \n",
    "            sns.histplot(data = adata_df[adata_df.Bin!='Null'],\n",
    "                 x=transcript, \n",
    "                 hue='Bin', \n",
    "                 bins=10000, \n",
    "                 binrange=(0,ymax_new),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True, \n",
    "                 common_norm=False,\n",
    "                 palette = ['Black','Red','Orange','Green','Teal','Blue'])\n",
    "            ax.set_xlabel(celltype)\n",
    "            ax.set_ylabel('Cumulative Distribution')\n",
    "            ax.set_title(transcript)\n",
    "            ax.set_ylim(0,1)\n",
    "            fig.savefig(dataPath+'figures/'+experimentName+'_region'+str(region)+'_'+transcript+'_histogram.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27cd7b-4f13-484d-8f6a-28ab67a3b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tb_pos_cells(adata,avg_signal_df, threshold, std_threshold,experimentName, region):\n",
    "    #add metrics to adata object\n",
    "    adata.obs.loc[avg_signal_df.index,'TB_std'] = avg_signal_df.std_signal\n",
    "    adata.obs.loc[avg_signal_df.index,'TB_mean'] = avg_signal_df.mean_signal\n",
    "    adata.obs.loc[avg_signal_df.index,'TB_topaverage'] = avg_signal_df.top_avg_signal\n",
    "\n",
    "    if experimentName=='202309251210_20230925-RitwicqA-TB_VMSC02401' and region=='2':\n",
    "        threshold = 250\n",
    "    \n",
    "    adata.obs['TB_class_from_images'] = 'High'\n",
    "    adata.obs.loc[adata.obs.TB_topaverage<=threshold,'TB_class_from_images'] = 'Low'\n",
    "    print('initial thresholding',adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "    adata.obs.loc[(adata.obs.TB_std<=std_threshold)&(adata.obs.TB_topaverage>threshold),'TB_class_from_images'] = 'Removed'\n",
    "    print('with sd cutoff',adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "\n",
    "    #run distance calculation\n",
    "    adata = tbcells_only_calculate_distance_to_tb(adata)\n",
    "\n",
    "    #print out initial counts, remove cells with high TB values and lone cells\n",
    "    adata.obs.loc[adata.obs.Cellbound3_high_pass>5e6,'TB_class_from_images']='Removed'\n",
    "    print('removed super high fluorescent cells', adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "    adata.obs.loc[adata.obs.distance_to_tb>400,'TB_class_from_images']='Removed' \n",
    "    print(\"removed lone cells\", adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "\n",
    "    if experimentName=='202305261458_TB-TEST3-MB_VMSC02401':\n",
    "        adata.obs.loc[adata.obs.center_x>4000,'TB_class_from_images'] = 'Removed'\n",
    "        print(adata.obs.TB_class_from_images.value_counts())\n",
    "    \n",
    "    adata.obs.TB_class_from_images.to_csv(dataPath+'cell_annotations/'+experimentName+'region'+str(region)+'TB_binary.csv')\n",
    "    adata.obs.TB_class_from_images.value_counts()   \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    sc.pl.spatial(adata,color='TB_class_from_images',spot_size=30,palette={'High': 'red','Low': 'lightgrey','Removed':'grey'},ax=ax)\n",
    "\n",
    "    sc.pl.violin(adata,['center_x','center_y'],groupby='TB_class_from_images')\n",
    "    sc.pl.violin(adata,['TB_std','TB_mean'],groupby='TB_class_from_images')\n",
    "    sc.pl.violin(adata,['TB_topaverage','Cellbound3_high_pass'],groupby='TB_class_from_images')\n",
    "    sc.pl.scatter(adata,x='TB_topaverage',y='TB_std',color='TB_class_from_images',size=30)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(10,10))\n",
    "    ax.axvline(8000,color='black')\n",
    "    ax.axvline(9000,color='black') #1 mm\n",
    "    sc.pl.spatial(adata,spot_size=20,color = 'TB_class_from_images',palette={'High': 'red','Low': 'lightgrey','Removed':'grey'},ax=ax)\n",
    "    fig.savefig(dataPath+'figures/'+experimentName+'region'+str(region)+'1mmscale_TBclass.pdf')       \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e3586-4356-45dd-98a9-2a8a823b9fb6",
   "metadata": {},
   "source": [
    "## 1. Load in final smartseq object, remove neutrophils, and edit gene names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e5d82-8bc8-4f13-a2a6-8d321344a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data = sc.read_h5ad(dataPath+'Annotated_h5ad/scRNAseq_MNP_SS2only.h5ad')\n",
    "sc_data = sc_data[sc_data.obs.leiden!='Neutrophil'].copy()\n",
    "sc.pl.umap(sc_data,color = 'leiden')\n",
    "sc_data.var_names = [i.replace('-','') for i in sc_data.var_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36dcc6d-10f2-4e00-b3df-087f82479d7f",
   "metadata": {},
   "source": [
    "## 2. Filter and QC the Vizgen h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190b91c-b056-427b-97af-9122a98eec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a table\n",
    "experiment_df = pd.DataFrame(columns = ['experimentName','region','clipx'])\n",
    "experiment_df.loc[0] = ['202305231432_TB-CTRL1-MB_VMSC02401','0',0]\n",
    "experiment_df.loc[1] = ['202305231432_TB-CTRL1-MB_VMSC02401','1',0]\n",
    "experiment_df.loc[2] = ['202305231432_TB-CTRL1-MB_VMSC02401','2',0]\n",
    "experiment_df.loc[3] = ['202305251147_TB-CTRL2-MB_VMSC02401','0',0]\n",
    "experiment_df.loc[4] = ['202305251147_TB-CTRL2-MB_VMSC02401','1',0]\n",
    "experiment_df.loc[5] = ['202305261458_TB-TEST3-MB_VMSC02401','1',2000]\n",
    "experiment_df.loc[7] = ['202309251210_20230925-RitwicqA-TB_VMSC02401','1',7500]\n",
    "experiment_df.loc[8] = ['202309251210_20230925-RitwicqA-TB_VMSC02401','2',2500]\n",
    "experiment_df.loc[9] = ['202310091253_AmandaS-TB-02_VMSC02401','0',0]\n",
    "experiment_df.loc[10] = ['202310091253_AmandaS-TB-02_VMSC02401','1',0]\n",
    "experiment_df.loc[11] = ['202310091253_AmandaS-TB-02_VMSC02401','2',0]\n",
    "experiment_df.loc[12] = ['202310111428_RitwicqA-TB-4b_VMSC02401','1',0]\n",
    "experiment_df.loc[13] = ['202310111428_RitwicqA-TB-4b_VMSC02401','2',0]\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c837c-f46f-4afd-8d87-08accb3cd03d",
   "metadata": {},
   "source": [
    "Set all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4810521d-803b-468a-a472-0b02e0d98343",
   "metadata": {},
   "source": [
    "## 3. Process the TB staining images [takes time+memory, you can skip this and run the next chunk if avg_signal_df.csv exists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d20e1-4e74-4192-90af-f5466490b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for jloc in experiment_df.index:\n",
    "    experimentName = experiment_df.experimentName[jloc]\n",
    "    region = experiment_df.region[jloc]\n",
    "    clipx = experiment_df.clipx[jloc]\n",
    "    print(experimentName, region, clipx)\n",
    "\n",
    "    filenames = os.listdir(processedDataPath+experimentName)\n",
    "    filename = [i for i in filenames if i.endswith('.h5ad')][0]\n",
    "    \n",
    "    ## Process the vizgen adata file and filter out damaged tissue\n",
    "    adata = load_vizgen_h5ad(processedDataPath = processedDataPath,experimentName=experimentName, filename = filename, region=region,\n",
    "                    min_volume=200, max_volume=5000, min_counts=20, min_dapi = 2000000, TB_threshold = 700000)\n",
    "    adata = filter_h5ad(adata)\n",
    "    show_spatial_plots(adata,clipx, experimentName,region)\n",
    "\n",
    "    #remove any damage\n",
    "    adata = adata[adata.obs.center_x>clipx].copy()\n",
    "    if experimentName == '202309251210_20230925-RitwicqA-TB_VMSC02401' and region=='1':\n",
    "        adata = adata[adata.obs.center_y<6500].copy()\n",
    "    sc.pl.spatial(adata,spot_size=50)\n",
    "    adata = sc_preprocess(adata)\n",
    "    \n",
    "    ## Load in the image data and calculate metrics for each segment using the antibody information\n",
    "    \n",
    "    #collect data from images\n",
    "    df = load_tb_image_information(dataPath=dataPath,experimentName=experimentName,region=region)\n",
    "    #calculate average signal per cell for each metric\n",
    "    avg_signal_df = make_average_gdf(df,adata)\n",
    "    print(avg_signal_df.shape, adata.shape)\n",
    "\n",
    "    #Save avg_signal_df\n",
    "    avg_signal_df.to_csv(dataPath+'avg_signal_df.csv')\n",
    "    \n",
    "    #Define TB positive cells\n",
    "    adata = assign_tb_pos_cells(adata,avg_signal_df, threshold,std_threshold,experimentName, region)\n",
    "\n",
    "    #normalize count data to polyA signal per cell\n",
    "    adata.layers['normalized_to_polyT'] = adata.layers['counts']/np.array(adata.obs.PolyT_high_pass).reshape(-1,1)*np.mean(adata.obs.PolyT_high_pass)\n",
    "    adata.layers['normalized_to_polyT'] = sparse.csr_matrix(adata.layers['normalized_to_polyT'])\n",
    "        \n",
    "    #skip these parts if there are not TB+ cells\n",
    "    if 'High' in set(adata.obs.TB_class_from_images):\n",
    "        \n",
    "        adata = calculate_distance_to_tb(adata)\n",
    "        adata.obs.distance_to_tb = adata.obs.distance_to_tb.astype('float')\n",
    "\n",
    "        adata_df, df_results = permutation_test_for_tb_loc(adata,layer=layer,binsize=binsize,perm_iterations=perm_iterations)\n",
    "        sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "\n",
    "        plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=50)\n",
    "    adata.write_h5ad(dataPath+'Annotated_h5ad_individual/'+experimentName+'_region'+str(region)+'_Annotated.h5ad')\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925845c4-6726-47d6-8679-7ff1c6dac5b0",
   "metadata": {},
   "source": [
    "## You can start here by loading in the avg_signal_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe46171-6d69-4435-829d-1b948663d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_signal_df = pd.read_csv(dataPath+'avg_signal_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e9a3c90-87f7-4776-a5e4-cd8bc1b620c3",
   "metadata": {},
   "source": [
    "#canonical markers:\n",
    "marker_dict = {}\n",
    "marker_dict['DC'] = ['Ccl22','Ccr2','Ccr7','Cd83','Cd86','Dpp4','Irf4','Irf8','Xcr1']\n",
    "marker_dict['AlvMac'] = ['Ccl6','Cd2','Clec4a2','Clec7a','Fabp4','Marco','Mrc1','Pparg']\n",
    "marker_dict['MatMoMac'] = ['C1qa','C1qb','C1qc','Fcgr1','Fcgr4']\n",
    "marker_dict['ImmMoMac'] = ['Apoe','Ccl9','Ccr2','Coro1a','Cx3cr1','Nr4a1','Plac8','Sell']\n",
    "marker_dict['Neutrophil'] = ['Csf3r','Cxcl2','Cxcr2','Il1r2','Mmp9']\n",
    "\n",
    "#these are the calculated markers\n",
    "marker_dict = {}\n",
    "marker_dict['DC'] =['Ccr7', 'Ccl22', 'Ly6d', 'Nr4a3', 'Xcr1', 'Dpp4', 'Irf4', 'Cd83']\n",
    "marker_dict['Neutrophil'] =['Cxcr2', 'Csf3r', 'Il1r2']\n",
    "marker_dict['AlvMac'] = ['Krt79', 'Plet1', 'Cd2', 'Car4', 'Mrc1', 'Marco', 'Tgfb2', 'Siglec1', 'Pparg']\n",
    "marker_dict['MatMoMac']=['Nos2', 'C1qc', 'C1qa', 'C1qb', 'Ms4a7', 'Sod2', 'Socs1', 'Cd40', 'Clec4e','Fcgr1' ]\n",
    "marker_dict['ImmMoMac']=['Nr4a1', 'Plac8', 'Cx3cr1', 'Sell', 'Spn', 'F13a1', 'Ccl9']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d6112-6d6f-4a73-a1de-af2672f85365",
   "metadata": {},
   "source": [
    "### 1. Plotting per-replicate values for each target transcript (Figure 6c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0badc80-b7f0-4567-9b56-7bbc3142cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in final df_results and find consensus genes, plot top ones with a dot for each replicate, show consensus on violin plots for smartseq data\n",
    "#for cumulative distribution plots, show on total dataset\n",
    "\n",
    "#1. make a file with all the genes and all the data points\n",
    "folder = dataPath+'Stats/'\n",
    "\n",
    "df = pd.DataFrame(columns = ['gene','stat','p_value','experiment','region'])\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "        \n",
    "    #use only the TB files\n",
    "    if 'CTRL' in file:\n",
    "        continue\n",
    "    if 'All' in file:\n",
    "        continue\n",
    "    if 'Total' in file:\n",
    "        continue\n",
    "    experiment = file.split('_')[1]\n",
    "    region = file.split('_')[3].split('.')[0]\n",
    "    \n",
    "    stats = pd.read_csv(folder+file)\n",
    "    stats.columns = ['gene','stat','remove','p_value']\n",
    "    del stats['remove']\n",
    "    stats['experiment'] = experiment\n",
    "    stats['region'] = region\n",
    "\n",
    "    df = pd.concat([df, stats],ignore_index=True)\n",
    "\n",
    "#plot each gene using a swarmplot\n",
    "average_df = pd.DataFrame(columns=['average'])\n",
    "for gene in list(set(df.gene)):\n",
    "    mean = np.mean(df.loc[df.gene==gene].stat)\n",
    "    average_df.loc[gene] = mean\n",
    "    \n",
    "average_df = average_df.sort_values('average')\n",
    "gene_list = list(average_df.index)\n",
    "\n",
    "df['average_value'] = 0\n",
    "for gene in average_df.index:\n",
    "    df.loc[df.gene==gene,'average_value']=average_df.loc[gene,'average']\n",
    "df\n",
    "df = df.sort_values('average_value')\n",
    "df.p_value[df.p_value>0.0001] = 0.1\n",
    "df.p_value[df.p_value<0.0001] = 0.0001\n",
    "df.p_value.value_counts()\n",
    "\n",
    "df.to_csv(dataPath+'Stats/statsAllTB_individualReplicates-excludingTB.csv')\n",
    "ax = sns.catplot(data=df.iloc[700:1125], \n",
    "                 x=\"stat\", \n",
    "                 y=\"gene\", \n",
    "                 hue=\"experiment\", \n",
    "                 #palette = ['red','orange','lightgrey'],\n",
    "                 kind=\"swarm\",\n",
    "                 aspect=1,\n",
    "                 height=10,\n",
    "                 row_order=gene_list)\n",
    "plt.savefig(dataPath+\"figures/replicate_samplestat_experiment_last700samples-excludingtb.pdf\", format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.catplot(data=df, \n",
    "                 x=\"stat\", \n",
    "                 y=\"gene\", \n",
    "                 hue=\"experiment\", \n",
    "                 #palette = ['red','orange','lightgrey'],\n",
    "                 kind=\"swarm\",\n",
    "                 aspect=1,\n",
    "                 height=10,\n",
    "                 row_order=gene_list)\n",
    "\n",
    "plt.savefig(dataPath+\"figures/replicate_samplestat_experiment-withoutTBcells.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324da24f-1778-42fc-9add-8c90c96970b8",
   "metadata": {},
   "source": [
    "### 2. Find genes that are up-, down-, and unregulated by proximity to TB (Figure 6d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2452d7-c11b-4df6-9683-1a3ca3bd3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_df\n",
    "\n",
    "#from kruskal-wallis test (for upregulated genes) p<0.01 compared to all the blanks, \n",
    "#carried out in prism using the statsAllTB_individualReplicates-excludingTB.csv file created above\n",
    "\n",
    "low_markers = list(average_df.loc[average_df.average< -0.2].index)\n",
    "print(low_markers)\n",
    "high_markers = ['Ifng','Socs1','Cd40','C1qc','Atf3','Ifi30','Adam19','Cd2','Tnf','Cxcr4','C1qb','Junb','Socs3',\n",
    "                'Nfkb2','Csf3r','Il1b','Irf7','Ifngr1','Sparc','Clec7a','Irf5','Jak2','Tgfb1','H2D1','Lgals3',\n",
    "                'Coro1b','Spn','Clec4e','Lamp1','Sirpa','H2Eb1','Hmox1','Hif1a','Itgal','Coro1a','Stat1','Irf1','Ly6e','Nos2','H2Ab1',\n",
    "                'H2K1','Cd74']\n",
    "\n",
    "\n",
    "neither = [x for x in list(average_df.index) if x not in low_markers+high_markers]\n",
    "neither = [x for x in neither if not x.startswith('Blank')]\n",
    "\n",
    "heatmap_labels = {'Up':high_markers,'Down':low_markers}\n",
    "heatmap_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46573fb-801c-4283-8146-7915e9ba1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "df_new.loc[df_new.gene.str.startswith(\"Blank\"),'gene']='Blank'\n",
    "df_new = df_new.loc[~df_new.gene.isin(neither)]\n",
    "df_new\n",
    "\n",
    "ax = sns.catplot(data=df_new, \n",
    "                 x=\"stat\", \n",
    "                 y=\"gene\", \n",
    "                 hue=\"experiment\", \n",
    "                 #palette = ['red','orange','lightgrey'],\n",
    "                 kind=\"swarm\",\n",
    "                 aspect=1,\n",
    "                 height=10,\n",
    "                 row_order=gene_list)\n",
    "\n",
    "plt.savefig(dataPath+\"figures/replicate_samplestat_experiment-withoutTBcells.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048cc5e-8255-4a4e-85d2-16bea7713b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a heatmap\n",
    "sc.pl.heatmap(sc_data,var_names = heatmap_labels, groupby='leiden',show_gene_labels=True,save = 'tbfinal_cleanmarkers.pdf')\n",
    "\n",
    "sc_data.var['UpNearTB']=False\n",
    "sc_data.var['UnchangedNearTB']=False\n",
    "sc_data.var['DownNearTB']=False\n",
    "\n",
    "sc_data.var.loc[high_markers,'UpNearTB']=True\n",
    "sc_data.var.loc[low_markers,'DownNearTB']=True\n",
    "sc_data.var.loc[neither,'UnchangedNearTB']=True\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars = ['UpNearTB','DownNearTB','UnchangedNearTB'],percent_top=None,inplace=True,log1p=False)\n",
    "sc.pl.violin(sc_data[sc_data.obs.leiden.isin(['moDerived Macrophage','Immature_moDerived Macrophage'])],['pct_counts_UpNearTB','pct_counts_DownNearTB','pct_counts_UnchangedNearTB'],\n",
    "             groupby='leiden',rotation=90,inner='quartile', save ='TB_affected_counts_violin.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde1db4-aaa1-46a1-9036-0bc014e12401",
   "metadata": {},
   "source": [
    "### 3. Combine all replicates into one merged h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cd397-d68b-49e5-b6a3-2e6c870aa3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the h5ads and merge them into one object, re-normalize\n",
    "\n",
    "\n",
    "\n",
    "adata = concatenate_h5ad_folder(input_folder=dataPath+'Annotated_h5ad_individual',\n",
    "                            output_folder=dataPath+'Annotated_h5ad',\n",
    "                            name = 'Total_concatenated_vizgen_h5ad',\n",
    "                            regex = ['date','slide','project','region'],\n",
    "                            regex_sep = '_',\n",
    "                            counts_threshold=0,\n",
    "                            genes_threshold=0,\n",
    "                            adata_file = 'None',\n",
    "                            save_frequency = 100)\n",
    "\n",
    "print(adata.obs['slide'].value_counts())\n",
    "\n",
    "adata.obs['Condition'] = 'Control'\n",
    "adata.obs.loc[~adata.obs.slide.isin(['TB-CTRL2-MB','TB-CTRL1-MB']),'Condition']='TB'\n",
    "print(adata.obs.groupby(['Condition','slide'])['fov'].count())\n",
    "\n",
    "adata.obs['genomics_personnel'] = 'Michael_Borja'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Amanda'),'genomics_personnel'] = 'Amanda_Seng'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Ritwicq'),'genomics_personnel'] = 'Ritwicq_Arjyal'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('20230925'),'genomics_personnel'] = 'Ritwicq_Arjyal'\n",
    "\n",
    "adata.obs['experiment_name'] = 'Control_1'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('20230925'),'experiment_name'] = 'TB_Mouse2_SectionA'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Ritwicq'),'experiment_name'] = 'TB_Mouse4_SectionB'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Amanda'),'experiment_name'] = 'TB_Mouse4_SectionC'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('TB-TEST3'),'experiment_name'] = 'TB_MouseX_Test3'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('TB-CTRL2'),'experiment_name'] = 'Ctrl_MouseX_Exp2'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('TB-CTRL1'),'experiment_name'] = 'Ctrl_MouseX_Exp1'\n",
    "\n",
    "print(adata.obs.experiment_name.value_counts())\n",
    "\n",
    "adata.obs['full_sample'] = adata.obs.experiment_name.astype('str')+'_'+adata.obs.region.astype('str')\n",
    "adata.obs.full_sample.value_counts()\n",
    "\n",
    "adata.obs.PolyT_high_pass = adata.obs.PolyT_high_pass.astype('float')\n",
    "adata.layers['normalized_to_polyT'] = adata.layers['counts']/np.array(adata.obs.PolyT_high_pass).reshape(-1,1)*np.mean(adata.obs.PolyT_high_pass)\n",
    "adata.layers['normalized_to_polyT'] = sparse.csr_matrix(adata.layers['normalized_to_polyT'])\n",
    "       \n",
    "    \n",
    "adata.obs.distance_to_tb = adata.obs.distance_to_tb.astype('float')\n",
    "adata.obs['grouped_distance_to_tb'] = '1_far'\n",
    "adata.obs.loc[adata.obs.distance_to_tb<1000,'grouped_distance_to_tb'] = '2_within_1_mm'\n",
    "adata.obs.loc[adata.obs.distance_to_tb<100,'grouped_distance_to_tb'] = '3_within_100_um'\n",
    "adata.obs.loc[adata.obs.distance_to_tb==0,'grouped_distance_to_tb'] = '4_TBPositive'\n",
    "adata.obs.loc[adata.obs.distance_to_tb<-1,'grouped_distance_to_tb'] = '5_Unclear'\n",
    "\n",
    "adata.obs.grouped_distance_to_tb.value_counts()\n",
    "adata.var.index = [i.replace(\"-\",\"\") for i in adata.var.index]\n",
    "\n",
    "#save this object with all the columns\n",
    "\n",
    "adata.write_h5ad(dataPath+'Annotated_h5ad/Total_annotated_vizgen_TB_20231120.h5ad')\n",
    "\n",
    "adata_keep = adata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3aac15-2166-42ef-92c6-69970b249fe1",
   "metadata": {},
   "source": [
    "### 3.5 Generate cumulative distribution plots for individual genes (Figure 6F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4d845-9952-4974-b98b-ffd9479b99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentName='AllTB'\n",
    "region='All'\n",
    "perm_iterations=1000\n",
    "binsize=100\n",
    "\n",
    "pval_threshold = 0.001\n",
    "stat_threshold = 0.5\n",
    "\n",
    "marker_dict = {'up':['Nos2'],\n",
    "              'down':['Lyve1'],\n",
    "              'neither':['Apoe']}\n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "\n",
    "adata_tb = adata[adata.obs.Condition=='TB'].copy()\n",
    "\n",
    "adata_df, df_results = permutation_test_for_tb_loc(adata_tb,layer,binsize,perm_iterations)\n",
    "sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=50)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=20)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6e732-0ab5-4904-8f21-d930ace27755",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentName='AllControl'\n",
    "region='All'\n",
    "perm_iterations=1000\n",
    "binsize=100\n",
    "\n",
    "pval_threshold = 0.001\n",
    "stat_threshold = 0.5\n",
    "\n",
    "marker_dict = {'up':['Nos2'],\n",
    "              'down':['Lyve1'],\n",
    "              'neither':['Apoe']}\n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "\n",
    "adata_tb = adata[adata.obs.Condition!='TB'].copy()\n",
    "\n",
    "adata_df, df_results = permutation_test_for_tb_loc(adata_tb,layer,binsize,perm_iterations)\n",
    "sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=50)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=20)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8eb68-5454-4721-8dd4-f54a6754922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from calculations with all samples together\n",
    "#note: top 30 genes from this method and the previous method are completely overlapping except for c1qb\n",
    "up_merged = sc_data.var.index[sc_data.var.UpNearTB]\n",
    "up_merged\n",
    "\n",
    "#from calculations with each sample separate \n",
    "#top 40\n",
    "up_separate = average_df.sort_values('average',ascending=False)[:30].index\n",
    "up_separate\n",
    "\n",
    "for gene in list(up_merged):\n",
    "    if gene in list(up_separate):\n",
    "        print(gene, \"is in both lists\")\n",
    "    else:\n",
    "        print(gene, \"is unique to the new calculation excluding TB+ cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e77999-6897-4319-b15c-26d7a61c02a7",
   "metadata": {},
   "source": [
    "### 4. Plot number of MTB+ cells from control and deprived FOV sections (Figure S6B-C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a318f1-8972-48c1-bbdf-457887673dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(adata.obs.groupby(['full_sample','TB_class_from_images'])['slide'].count())\n",
    "newdf = pd.DataFrame(index = list(set(adata.obs.full_sample)),columns = ['experiment','High','Low','Removed'])\n",
    "for i,j in df.index:\n",
    "    exp = i \n",
    "    tb_class = j\n",
    "    value = df.loc[i,j][0]\n",
    "    newdf.loc[i,j] = value\n",
    "    \n",
    "newdf.experiment = newdf.index.copy()\n",
    "newdf_small = newdf[['experiment','High']]\n",
    "newdf_small = newdf_small.sort_values(\"High\")\n",
    "index_order = newdf_small.index\n",
    "#plot a bar plot\n",
    "newdf_small.plot(x='experiment', kind='bar', stacked=True,\n",
    "        title='Number of cells classified as TB+ by section',color = 'red')\n",
    "plt.tight_layout()\n",
    "plt.savefig(dataPath+'figures/TB_pos_cells_by_sample_bar.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f4da4-64fc-42d8-9c08-be7e559b8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['total'] = newdf.High+newdf.Low+newdf.Removed\n",
    "newdf_small = newdf[['experiment','total']]\n",
    "newdf_small = newdf_small.loc[index_order]\n",
    "newdf_small\n",
    "\n",
    "#plot a bar plot\n",
    "newdf_small.plot(x='experiment', kind='bar', stacked=True,\n",
    "        title='Total number of cells by section',color = 'grey')\n",
    "plt.tight_layout()\n",
    "plt.savefig(dataPath+'figures/all_cells_by_sample_bar.pdf',format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01777d-f475-4335-a263-9506dd3414da",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_small = newdf[['experiment','High','total']]\n",
    "newdf_small['percent'] = newdf_small['High']*100/newdf_small['total']\n",
    "newdf_small = newdf_small[['experiment','percent']]\n",
    "newdf_small = newdf_small.loc[index_order]\n",
    "newdf_small\n",
    "\n",
    "#plot a bar plot\n",
    "newdf_small.plot(x='experiment', kind='bar', stacked=True,\n",
    "        title='Percent TB+ positive cells by section',color = 'grey')\n",
    "plt.tight_layout()\n",
    "plt.savefig(dataPath+'figures/percent_tb_cells_by_sample_bar.pdf',format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768aa2e-52b4-4361-a663-6ba1f050c5ce",
   "metadata": {},
   "source": [
    "### 5. Validating that signature of TB-near cells is not present in control sections (where TB+ cells are rare artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd941e9-1896-48fe-bd0a-408dfd955b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in both data frames and compare the gene signatures\n",
    "ctrl_stats = pd.read_csv(dataPath+'Stats/statsAllControl_regionAll.csv',index_col=0)\n",
    "ctrl_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57081ec7-2781-478a-92da-f4b654381c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in both data frames and compare the gene signatures\n",
    "tb_stats = pd.read_csv(dataPath+'Stats/statsAllTB_regionAll.csv',index_col=0)\n",
    "tb_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8873e-7e18-4617-b56e-24c25a4bb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every gene, plot the tb sample_stat vs ctrl sample_stat\n",
    "#make a combined data frame\n",
    "all_stats = pd.DataFrame(index = tb_stats.index)\n",
    "all_stats['tb_sample_stat'] = tb_stats['sample_stat'].copy()\n",
    "all_stats['tb_pval'] = tb_stats['p_value'].copy()\n",
    "\n",
    "for i in all_stats.index:\n",
    "    all_stats.loc[i,'Ctrl_sample_stat'] = ctrl_stats.loc[i,'sample_stat']\n",
    "    all_stats.loc[i,'Ctrl_sample_pval'] = ctrl_stats.loc[i,'p_value']\n",
    "    \n",
    "all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0cffb-c849-4755-bf78-28815b29c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by tb_sample_stat and plot both tb and control stats\n",
    "all_stats = all_stats.sort_values('tb_sample_stat')\n",
    "all_stats['gene'] = all_stats.index.copy()\n",
    "\n",
    "#plot a volcano plot\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "ax.scatter(x = all_stats.tb_sample_stat, y=-np.log10(all_stats.tb_pval))\n",
    "ax.set_xlabel('difference in means, Bin1 - Null')\n",
    "ax.set_ylabel('-log p value')\n",
    "ax.set_title('TB volcano plot')\n",
    "\n",
    "for i in range(all_stats.shape[0]):\n",
    " ax.text(x=all_stats.tb_sample_stat[i],y=-np.log10(all_stats.tb_pval[i]),s=all_stats.gene[i], \n",
    "          color='black',size=8,rotation=30)\n",
    "\n",
    "print(all_stats.loc[abs(all_stats.tb_sample_stat)>0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f2211-2c74-49a0-a313-626d95624bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a volcano plot\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "ax.scatter(x = all_stats.Ctrl_sample_stat, y=-np.log10(all_stats.Ctrl_sample_pval))\n",
    "ax.set_xlabel('difference in means, Bin1 - Null')\n",
    "ax.set_ylabel('-log p value')\n",
    "ax.set_title('Ctrl volcano plot')\n",
    "\n",
    "for i in range(all_stats.shape[0]):\n",
    " ax.text(x=all_stats.Ctrl_sample_stat[i],y=-np.log10(all_stats.Ctrl_sample_pval[i]),s=all_stats.gene[i], \n",
    "          color='black',size=8,rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f417e-4b90-49b3-a96e-9e16c4a78d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a table comparing the genes that are significantly altered in the TB samples vs those significantly altered in the control samples\n",
    "tb_up = all_stats.gene[all_stats.tb_sample_stat>0.05]\n",
    "tb_down = all_stats.gene[all_stats.tb_sample_stat<-0.05]\n",
    "tb_neither = all_stats.gene[(all_stats.tb_sample_stat<0.05)&(all_stats.tb_sample_stat>-0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7175a-b45e-4f48-8962-8aac785d9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tb_up))\n",
    "x = all_stats.loc[tb_up,'Ctrl_sample_stat']>0.05\n",
    "all_stats.loc[x[x].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9436cd8-8bd1-41d1-9eb4-bf2acf86bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tb_down))\n",
    "x = all_stats.loc[tb_down,'Ctrl_sample_stat']<-0.05\n",
    "all_stats.loc[x[x].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea792e9-c3f9-4084-934c-4af3d98aaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_up = tb_up[~tb_up.isin(['C1qa','C1qb'])]\n",
    "tb_down = tb_down[~tb_down.isin(['Lyve1','Dusp1','Itga6','Scarf2','Ly6e','Atf4','Col4a1','H2D1','Car4','Lamp1'])]\n",
    "\n",
    "tb_up = [i for i in tb_up if not i.startswith('Blank')]\n",
    "tb_down = [i for i in tb_down if not i.startswith('Blank')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde96fc-079f-4003-b038-519a4d35b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-run the violin plots with these genes\n",
    "condition = 'TBsubtractingControls_All'\n",
    "allprobes = [i for i in list(all_stats.index) if not i.startswith('Blank')]\n",
    "\n",
    "sc_data.var['UpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(tb_up),'UpNearTB'] = True\n",
    "\n",
    "sc_data.var['DownNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(tb_down),'DownNearTB'] = True\n",
    "\n",
    "sc_data.var['NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(allprobes),'NotUpNearTB'] = True\n",
    "sc_data.var.loc[sc_data.var['UpNearTB']==True,'NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var['DownNearTB']==True,'NotUpNearTB'] = False\n",
    "\n",
    "sc.pl.heatmap(sc_data,tb_up,groupby='leiden',show_gene_labels=True)\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','NotUpNearTB'],inplace=True)\n",
    "sc.pl.umap(sc_data,color = ['leiden'])\n",
    "sc.pl.umap(sc_data,color = ['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'])\n",
    "sc.pl.umap(sc_data,color = ['total_counts_NotUpNearTB','pct_counts_NotUpNearTB'])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "#sc.pl.violin(sc_data,['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'],groupby='leiden',rotation=90)\n",
    "sc.pl.violin(sc_data,['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_UP_limit01_strict_TB.pdf',ax=ax)\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "sc.pl.violin(sc_data,['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_Down_limit01_strict_TB.pdf',ax=ax)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "sc.pl.violin(sc_data,['pct_counts_NotUpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_NEITHER_limit01_strict_TB.pdf',ax=ax)\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ff02f-fed5-40b9-b000-7fa8b6ee27ac",
   "metadata": {},
   "source": [
    "### 6. Selecting cells that are confidently Monocyte/Macrophages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a02a0-470e-40a5-9d0f-e2e43856b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list from tabula muris senis specific to myeloid cells, expressed in all myeloid cells but no others:\n",
    "gene_list_from_tms = ['C1qb',\n",
    " 'C1qc',\n",
    " 'Clec4a2',\n",
    " 'Dnase1l3',\n",
    " 'Ms4a7',\n",
    " 'Sell',\n",
    " 'Trem2',\n",
    " 'Mmp9',\n",
    " 'Clec4e']\n",
    "\n",
    "marker_list_threshold = 5 #threshold for how many counts of the above need to be in a cell\n",
    "marker_dict = {'High':['Nos2'], 'Low':['Lyve1'],'Neither':['Apoe']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198df7d9-b0c8-4d7f-b6ef-4ba63ad37110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show Lyve1 expression in super confident macrophages\n",
    "#calculate qc metrics for MarkerGenes\n",
    "#add info to the adata object\n",
    "adata.var['MarkerGenes'] = False\n",
    "adata.var.loc[adata.var.index.isin(gene_list_from_tms),'MarkerGenes'] = True\n",
    "\n",
    "sc.pp.calculate_qc_metrics(adata, expr_type='counts', percent_top=None,qc_vars=['MarkerGenes'], layer='counts', inplace=True, log1p=False)\n",
    "\n",
    "cm = adata[adata.obs.total_counts_MarkerGenes>5].shape[0]\n",
    "    #show how many cells have any of the marker genes\n",
    "print(\"cells with marker gene expression: \", cm)\n",
    "    \n",
    "    #assign confident macrophages\n",
    "adata.obs['confident_celltype'] = 'Unknown'\n",
    "adata.obs.loc[adata.obs.total_counts_MarkerGenes>marker_list_threshold,'confident_celltype'] = 'Immune'\n",
    "\n",
    "#show Lyve1 expression\n",
    "sc.pl.violin(adata[adata.obs.confident_celltype=='Immune'],'Lyve1',groupby='grouped_distance_to_tb',stripplot=False,layer='normalized_to_polyT')\n",
    "sc.pl.violin(adata[adata.obs.confident_celltype=='Unknown'],'Lyve1',groupby='grouped_distance_to_tb',stripplot=False,layer='normalized_to_polyT')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_ylim(0,20)\n",
    "#ax.set_yscale('log')\n",
    "sc.pl.violin(adata[adata.obs.confident_celltype=='Immune'],'Lyve1',groupby='grouped_distance_to_tb',stripplot=False,layer='normalized_to_polyT',inner='quartile',title='MonoMac',ax=ax,\n",
    "             save='_immune_lyve1_violin.pdf')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_ylim(0,20)\n",
    "sc.pl.violin(adata[adata.obs.confident_celltype=='Unknown'],'Lyve1',\n",
    "             groupby='grouped_distance_to_tb',stripplot=False,\n",
    "             layer='normalized_to_polyT',inner='quartile',\n",
    "             title='Remainder',ax=ax,save='_remainder_lyve1_violin.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de773c78-f08b-4a17-bcae-c7a71f8f0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remake some of the cumulative distribution plots with confident cell type markers\n",
    "experimentName='AllTB_ConfidentMonoMac'\n",
    "region='All'\n",
    "\n",
    "binsize=100\n",
    "\n",
    "marker_dict = {'up':['Nos2'], #['Cd74','H2K1','Nos2','C1qb','Hmox1']\n",
    "              'down':['Lyve1'],\n",
    "              'neither':['Apoe'],\n",
    "              'MacrophageMarkersFromTMS':['MacroMarkers']}\n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "\n",
    "\n",
    "adata_tb = adata[adata.obs.Condition=='TB'].copy()\n",
    "\n",
    "#add a column to adata_df with the summed counts of the macrophage markers\n",
    "if isinstance(adata_tb.layers[layer], scipy.sparse._csr.csr_matrix):\n",
    "    adata_df = pd.DataFrame.sparse.from_spmatrix(adata_tb.layers[layer])\n",
    "    adata_df = adata_df.sparse.to_dense()\n",
    "else:\n",
    "    adata_df = pd.DataFrame(adata_tb.layers[layer])\n",
    "adata_df.columns = adata_tb.var.index\n",
    "adata_df.index = adata_tb.obs.index\n",
    "adata_df['MacroMarkers'] = adata_tb.obs.total_counts_MarkerGenes.copy()\n",
    "adata_df['distance_real'] = adata_tb.obs['distance_to_tb'].copy()\n",
    "adata_df.columns = [i.replace('-','') for i in adata_df.columns]\n",
    "adata_df['Bin'] = 'Null'\n",
    "#for the first 4 bins, plot the distribution on top of this one in a different color\n",
    "adata_df.loc[(adata_df.distance_real>=6*binsize) & (adata_df.distance_real<7*binsize),'Bin'] = 'Bin7'\n",
    "adata_df.loc[(adata_df.distance_real>=3*binsize) & (adata_df.distance_real<4*binsize),'Bin'] = 'Bin4'\n",
    "adata_df.loc[(adata_df.distance_real>=2*binsize) & (adata_df.distance_real<3*binsize),'Bin'] = 'Bin3'\n",
    "adata_df.loc[(adata_df.distance_real>=binsize) & (adata_df.distance_real<2*binsize),'Bin'] = 'Bin2'\n",
    "adata_df.loc[adata_df.distance_real<binsize,'Bin'] = 'Bin1'\n",
    "adata_df.loc[adata_df.distance_real==0,'Bin'] = 'Bin0'\n",
    "print(\"number of cells per bin: \",adata_df.Bin.value_counts())\n",
    "adata_df = adata_df.sort_values('Bin',ascending=True)\n",
    "\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=100)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ab496-d907-481e-a085-00a0b252a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sub = adata[adata.obs.grouped_distance_to_tb.isin(['3_within_100_um','4_TBPositive'])].copy()\n",
    "adata_sub = adata_sub[adata_sub.obs.confident_celltype=='Immune'].copy()\n",
    "adata_sub\n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "if isinstance(adata_sub.layers[layer], scipy.sparse._csr.csr_matrix):\n",
    "    adata_df = pd.DataFrame.sparse.from_spmatrix(adata_sub.layers[layer])\n",
    "    adata_df = adata_df.sparse.to_dense()\n",
    "else:\n",
    "    adata_df = pd.DataFrame(adata_sub.layers[layer])\n",
    "adata_df.columns = adata_sub.var.index\n",
    "adata_df.index = adata_sub.obs.index\n",
    "adata_df['Bin'] = adata_sub.obs['grouped_distance_to_tb'].copy()\n",
    "adata_df.columns = [i.replace('-','') for i in adata_df.columns]\n",
    "\n",
    "#permutation test ~43 iterations/second\n",
    "df_results = pd.DataFrame(columns=['sample_stat','average_stat','p_value'])\n",
    "for transcript in tqdm(adata_df.columns[:140]):\n",
    "    ref_average = np.mean(adata_df.loc[adata_df['Bin']=='3_within_100_um',transcript])\n",
    "        #print(ref_average)\n",
    "                              \n",
    "    sample_stat = np.mean(adata_df.loc[adata_df['Bin']=='4_TBPositive',transcript]) - ref_average #calculate the difference in means between your bin1 distribution and the null distribution\n",
    "    stats = np.zeros(perm_iterations)\n",
    "    for k in range(perm_iterations):\n",
    "        labels = np.random.permutation((adata_df['Bin'] == '4_TBPositive').values) #randomly rearrange the bin labels so you get another sample in 'Bin1'\n",
    "        stats[k] = np.mean(adata_df[transcript][labels]) - ref_average #for each of 1000 iterations, calculate the difference between the random Bin1 Nos2 values and the null distribution\n",
    "    \n",
    "    if sample_stat>=0:\n",
    "        p_value = np.mean(stats > sample_stat)\n",
    "    if sample_stat<0:\n",
    "        p_value = np.mean(stats < sample_stat)\n",
    "    #save the stat and p-value per transcript\n",
    "    df_results.loc[transcript] = [sample_stat,np.mean(stats),p_value] \n",
    "\n",
    "df_results = df_results.sort_values('p_value',ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847a967-b199-4b09-b586-f9d83f21139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.sort_values('sample_stat',ascending=False)\n",
    "print(df_results.p_value[df_results.p_value>0].min())\n",
    "df_results.loc[df_results.p_value==0,'p_value'] = 0.9/perm_iterations\n",
    "df_results.to_csv(dataPath+'Stats/AllMonoMacInfectedVsNeighbors.csv')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(x = df_results.sample_stat, y=-np.log10(df_results.p_value))\n",
    "plt.xlabel('difference in means, Bin1 - Null')\n",
    "plt.ylabel('-log p value')\n",
    "\n",
    "for i in range(df_results.shape[0]):\n",
    "    plt.text(x=df_results.sample_stat[i],y=-np.log10(df_results.p_value[i]),s=df_results.index[i], \n",
    "            fontdict=dict(color='black',size=10))\n",
    "    \n",
    "plt.savefig(dataPath+'figures/volcano_InfectedVsNeighbors.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d4a3d-a6d3-4fba-961c-42ec3f778ecc",
   "metadata": {},
   "source": [
    "### Figure 7A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4769954-7b14-47ca-a73f-39ccdd8aac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['gene'] = df_results.index.copy()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d502e8-cc6c-41c2-8cff-3b192e18ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc['Sirpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001d81a-386d-4506-9ffa-475c40253616",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(data=df_results[(df_results.p_value<0.001)&(abs(df_results.sample_stat)>0.5)], \n",
    "                 x=\"gene\", \n",
    "                 y=\"sample_stat\",  \n",
    "                 kind=\"swarm\",\n",
    "                 aspect=3,\n",
    "                 height=3,\n",
    "                 s=100,\n",
    "                 row_order=gene_list)\n",
    "ax.set_xticklabels(rotation=90)\n",
    "plt.axhline(0,c='black')\n",
    "plt.savefig(dataPath+\"figures/monomac_swarmplot_TBPos_vs_Neighbors.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e1708-de46-483d-a723-c113b4072880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show Dnase1l3 expression \n",
    "sc.pl.violin(adata,'Dnase1l3',groupby='TB_class_from_images')\n",
    "sc.pl.violin(sc_data,['Dnase1l3','Nos2'],groupby='leiden',rotation=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popv",
   "language": "python",
   "name": "popv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
