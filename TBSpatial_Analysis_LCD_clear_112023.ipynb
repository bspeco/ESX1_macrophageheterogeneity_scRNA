{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc19833a",
   "metadata": {},
   "source": [
    "### Quantify image-based metrics of TB stain with single-cell segmentation geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e002fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import anndata as ad\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.affinity import translate\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n",
    "import scanpy as sc\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da4c4635-2089-4936-b216-86fde92e9f6d",
   "metadata": {},
   "source": [
    "Extra information:\n",
    "Panel: https://docs.google.com/spreadsheets/d/1RS2xFdSDkf78g5Sd5VZyuJSCvmJ6rur6fHlNgilKsgY/edit#gid=287597825\n",
    "\n",
    "Dendritic Cell top genes: ['Ccr7', 'Ccl22', 'Ly6d', 'Nr4a3', 'Xcr1', 'Dpp4', 'Irf4', 'Cd83']\n",
    "Neutrophil top genes: ['Cxcr2', 'Csf3r', 'Il1r2']\n",
    "Alveolar Macrophage top genes: ['Krt79', 'Plet1', 'Cd2', 'Car4', 'Mrc1', 'Marco', 'Tgfb2', 'Siglec1', 'Pparg']\n",
    "moDerived Macrophage top genes: ['Nos2', 'C1qc', 'C1qa', 'C1qb', 'Ms4a7', 'Sod2', 'Socs1', 'Cd40', 'Clec4e’,’Fcgr1’ ,’Ly6c2’]\n",
    "Immature_moDerived Macrophage top genes: ['Nr4a1', 'Plac8', 'Cx3cr1', 'Sell', 'Spn', 'F13a1', 'Ccl9', 'Ly6c2']\n",
    "MTB-high: ['Dnase1l3']\n",
    "\n",
    "X_spatial and center_x, center_y are in micron units\n",
    "set binsize to 100 for 100 um\n",
    "\n",
    "Thresholds: \n",
    "    minimum top average: 300\n",
    "    minimum st dev: 150\n",
    "    remove cells >400 um from 2nd closest TB+ neighbor\n",
    "    remove cells with >5 million cellbound 3 high pass\n",
    "    \n",
    "Extra thresholds: \n",
    "    Test3: Cut off left 2000 microns, exclude anything with center_x > 4000\n",
    "    202309251210_20230925-RitwicqA-TB_VMSC02401 region 1: Cut off left 7500 microns, bottom >6500 microns\n",
    "    202309251210_20230925-RitwicqA-TB_VMSC02401 region 2: Cut off left 2500 microns, **Min top avg = 250**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb2eab-5871-4aa5-9c29-868051d2a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_h5ad_folder(input_folder,\n",
    "                            output_folder='None',\n",
    "                            name = 'concatenated_10x_output',\n",
    "                            regex = ['donor','tissue','anatomical_position','method','sample','replicate','notes'],\n",
    "                            regex_sep = '_',\n",
    "                            counts_threshold=1000,\n",
    "                            genes_threshold=100,\n",
    "                            adata_file = 'None',\n",
    "                            save_frequency = 100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take output files from decontx processing and concatenate into anndata object\n",
    "    \"\"\"\n",
    "    \n",
    "    if output_folder=='None':\n",
    "        output_folder=input_folder\n",
    "    \n",
    "    if not os.path.isdir(input_folder):\n",
    "        raise SyntaxError('Input folder cannot be found')   \n",
    "        \n",
    "    if not os.path.isdir(output_folder):\n",
    "        raise SyntaxError('output folder cannot be found')   \n",
    "    \n",
    "    adata = sc.AnnData()\n",
    "        \n",
    "    files = [i for i in os.listdir(input_folder) if i.endswith(('.h5ad','.h5ad.gz'))]\n",
    "    print(\"first file: \",files[0])\n",
    "    count = 0\n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        \n",
    "        info = file.split(\".\")[0] #assuming information is present in the filename\n",
    "        \n",
    "        #add something to check whether a given sample is already present in the adata file\n",
    "        if adata_file!='None':\n",
    "            if info in list(adata.obs['10X_run']):\n",
    "                print('The sample ', info,' is already in the object. Skipping.')\n",
    "                continue\n",
    "        info_split = info.split(regex_sep)\n",
    "        if len(info_split)<len(regex):\n",
    "            print('Warning: the sample ',info,' does not have enough metadata information, ',regex[len(info_split):],' will be excluded')\n",
    "            regex_fix = regex[:len(info_split)]\n",
    "        else:\n",
    "            regex_fix = regex\n",
    "            \n",
    "            \n",
    "        print('reading ',file)\n",
    "        adata_interim = sc.read_h5ad(os.path.join(input_folder,file))\n",
    "        \n",
    "        #add in .obs - this depends on the actual metadata format\n",
    "        print('adding .obs columns to anndata object')\n",
    "        \n",
    "        adata_interim.obs['full_sample'] = info\n",
    "           \n",
    "        for n in range(0,len(regex_fix)):\n",
    "            adata_interim.obs[regex_fix[n]] = info.split(regex_sep)[n]\n",
    "        \n",
    "        adata_interim.obs['cell_id'] = adata_interim.obs['full_sample'] + \"_\" + adata_interim.obs.index.astype('str')\n",
    "        adata_interim.obs.set_index('cell_id',inplace=True)\n",
    "        \n",
    "        try:\n",
    "            del adata_interim.obsm\n",
    "        except:\n",
    "            adata_interim\n",
    "        \n",
    "        for obs_column in adata.obs.columns:\n",
    "            if \".\" in obs_column:\n",
    "                adata.obs[obs_column] = adata.obs[obs_column].astype('str')\n",
    "            \n",
    "        if adata.shape[0]>1:  \n",
    "            adata = ad.concat([adata,adata_interim],join='outer',merge='unique')\n",
    "            print('added to adata')\n",
    "        else:\n",
    "            adata = adata_interim.copy()\n",
    "            print('copying interim')\n",
    "            \n",
    "        adata.obs = adata.obs.astype('str')\n",
    "        count = count+1\n",
    "        \n",
    "        if count == save_frequency:\n",
    "            adata.write_h5ad(os.path.join(output_folder,name+'.h5ad'))\n",
    "            count=0\n",
    "        \n",
    "        gc.collect()\n",
    "            \n",
    "    \n",
    "    adata.write_h5ad(os.path.join(output_folder,name+'.h5ad'))\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e267a19-f7d3-4d0c-ae86-defef800c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def load_image_roi(file_name, window_coords):\n",
    "    try:\n",
    "        with rio.open(file_name) as aws_file:\n",
    "            roi = aws_file.read(1, window=rio.windows.Window(*window_coords))\n",
    "    except OSError:\n",
    "        print(f\"File read error on {file_name}\")\n",
    "        roi = np.zeros([window_coords[3],window_coords[2]])\n",
    "        \n",
    "    return np.squeeze(roi)\n",
    "\n",
    "def convert_eight_bit(img):\n",
    "    # Normalize contrast before reducing bit depth\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    norm_img = clahe.apply(img)    \n",
    "    bg_subtract = norm_img - norm_img.min()\n",
    "    \n",
    "    if bg_subtract.max() == 0:\n",
    "        return np.zeros(img.shape, dtype=np.uint8)\n",
    "    else:\n",
    "        range_norm = bg_subtract / bg_subtract.max()      \n",
    "        return np.array(range_norm * 255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710fc6e-4dd8-439f-ba6d-4e27c7e02c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tb_image_information(dataPath, experimentName, region):\n",
    "    \n",
    "    #initialize a dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    #iterate through the z planes - in this case there are 7\n",
    "    for z in range(0,7):\n",
    "        z_level = str(z)\n",
    "        print('z_level: ', z_level)\n",
    "    \n",
    "        # Segmentation boundaries\n",
    "        geometries = gpd.read_parquet(\n",
    "            os.path.join(dataPath, experimentName, 'region_' + region, 'cell_boundaries.parquet')).set_index('EntityID')\n",
    "    #print('Segmentation geometries loaded.')\n",
    "\n",
    "    # TB stain channel image, AKA cellbound3\n",
    "        TBmosaicPath = os.path.join(\n",
    "            dataPath, experimentName, 'region_' + region, 'images', 'mosaic_Cellbound3_z' + z_level + '.tif')\n",
    "\n",
    "    # DAPI stain channel image\n",
    "        DAPImosaicPath = os.path.join(\n",
    "            dataPath, experimentName, 'region_' + region, 'images', 'mosaic_DAPI_z' + z_level + '.tif')\n",
    "    \n",
    "    # Cellbound2 stain channel image\n",
    "        Cellbound2mosaicPath = os.path.join(\n",
    "            dataPath, experimentName, 'region_' + region, 'images', 'mosaic_Cellbound2_z' + z_level + '.tif')\n",
    "\n",
    "    #print('Mosaic filepaths loaded.')\n",
    "\n",
    "    # Micron to mosaic pixel transform\n",
    "        transformationMatrix = np.loadtxt(\n",
    "            os.path.join(dataPath, experimentName, 'region_' + region, 'images', 'micron_to_mosaic_pixel_transform.csv'))\n",
    "    \n",
    "    # Convert transformation matrix to correct affine transformation format for Geopandas\n",
    "        t = transformationMatrix\n",
    "        affine_matrix = [t[0,0], t[0,1], t[1,0], t[1,1], t[0,2], t[1,2]]\n",
    "\n",
    "    #print('Micron to mosaic pixel transform loaded.')\n",
    "\n",
    "    # Create new geodataframe column with mosaic pixel units\n",
    "        geometries_mosaic = geometries.copy()\n",
    "        geometries_mosaic['Geometry'] = geometries['Geometry'].affine_transform(affine_matrix)\n",
    "\n",
    "    #print('Mosaic geometries calculated.')\n",
    "\n",
    "    # Check that we have the right coordinates by overlaying with DAPI channel\n",
    "    # What are the dimensions of the overall experiment?\n",
    "        s = rio.open(DAPImosaicPath)\n",
    "        print('Dimensions of experiment are ' + str(s.width) + ' x ' + str(s.height) + ' in pixels.')\n",
    "\n",
    "        gdf = geometries_mosaic.copy()\n",
    "        gdf = gdf[gdf['ZIndex'] == int(z_level)]\n",
    "\n",
    "        shapes = list(gdf['Geometry'])\n",
    "        masks = []\n",
    "\n",
    "        with rio.open(TBmosaicPath) as src:\n",
    "            for shape in tqdm(shapes):\n",
    "                out_image, _ = mask(src, shape.geoms, crop=True)\n",
    "                masks.append(out_image)\n",
    "        \n",
    "    # Save array of pixel intensities for each cell\n",
    "        gdf['TB_intensities'] = pd.Series(dtype='object')\n",
    "    #for i in tqdm(range(len(gdf))):\n",
    "        #gdf.loc[:,'TB_intensities'].loc[gdf.index[i]] = masks[i][np.nonzero(masks[i])]\n",
    "    \n",
    "    \n",
    "    #all nonzero TB intensities for each cell\n",
    "        gdf['TB_intensities'] = [masks[i][np.nonzero(masks[i])] for i in range(len(gdf))] \n",
    "    \n",
    "    #all TB intensities for each cell, including zeros\n",
    "        gdf['TB_spatial'] = [masks[i].squeeze() for i in range(len(gdf))] \n",
    "\n",
    "    # Calculate some metrics\n",
    "\n",
    "    # Sum signal\n",
    "        gdf['sum_signal'] = [gdf.iloc[i]['TB_intensities'].sum() for i in range(len(gdf))]\n",
    "\n",
    "    # Mean (excluding zeros)\n",
    "        gdf['mean_signal'] = [gdf.iloc[i]['TB_intensities'].mean() for i in range(len(gdf))]\n",
    "    \n",
    "    # Median (excluding zeros)\n",
    "        gdf['median_signal'] = [np.median(gdf.iloc[i]['TB_intensities']) for i in range(len(gdf))]\n",
    "    \n",
    "    # Standard deviation (excluding zeros)\n",
    "        gdf['std_signal'] = [gdf.iloc[i]['TB_intensities'].std() for i in range(len(gdf))]\n",
    "\n",
    "    # Average of top 100 values\n",
    "        gdf['top_avg_signal'] = [np.sort(gdf.iloc[i]['TB_spatial'])[::-1][:100].mean() for i in range(len(gdf))]\n",
    "\n",
    "    #create a data frame we can add to for each z plane:\n",
    "        add = gdf[['ZIndex','sum_signal','mean_signal','median_signal','std_signal','top_avg_signal']]\n",
    "        df = pd.concat([df,add])\n",
    "    return df\n",
    "    \n",
    "def make_average_gdf(df,adata):\n",
    "\n",
    "#find the mean values for each entity across z positions\n",
    "#add a binary classifier to adata\n",
    "    avg_signal_df = pd.DataFrame(columns=df.columns)\n",
    "    for ind in tqdm(list(set(df.index))):\n",
    "        sub = df.loc[ind]\n",
    "        avg = sub.mean(axis=0)\n",
    "        avg_signal_df.loc[ind] = avg\n",
    "\n",
    "    avg_signal_df.index = [str(i) for i in avg_signal_df.index]\n",
    "\n",
    "    #subset to only cells that are included in the final object\n",
    "    avg_signal_df['Entity_ID'] = avg_signal_df.index.astype('str').copy()\n",
    "    avg_signal_df = avg_signal_df[avg_signal_df.Entity_ID.isin(list(adata.obs.index))].copy()\n",
    "    avg_signal_df.set_index('Entity_ID',inplace=True)\n",
    "    print(avg_signal_df.shape)\n",
    "\n",
    "    return avg_signal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956fd07-eedf-4e11-8878-9067962dcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vizgen_h5ad(processedDataPath,experimentName, filename, region,\n",
    "                    min_volume=200, max_volume=5000, min_counts=20, min_dapi = 2000000, TB_threshold = 700000):\n",
    "    \n",
    "    #read in the h5ad file\n",
    "    adata = sc.read_h5ad(processedDataPath+experimentName+'/'+filename)\n",
    "\n",
    "    #print the number of cells, cells per region, and show the object\n",
    "    print('number of cells in unfiltered dataset: ',adata.shape[0])\n",
    "    print('cells per region: ', adata.obs.region.value_counts())\n",
    "\n",
    "    #filter to one region at a time\n",
    "    adata = adata[adata.obs.region==region].copy()\n",
    "    adata\n",
    "\n",
    "    # Calculate total counts\n",
    "    adata.obs['total_counts'] = adata.X.toarray().sum(axis=1)\n",
    "    adata.obs['log_total_counts'] = np.log(adata.obs['total_counts'] + 1)\n",
    "    \n",
    "    #print graphs\n",
    "    #Create thresholds based on the plots above, and plot those lines onto the data. \n",
    "    fig, axes = plt.subplots(1,4, figsize=(12,4))\n",
    "\n",
    "    # Cell volume\n",
    "    bins = np.logspace(0,4,20)\n",
    "    ax = axes[0]\n",
    "    ax.hist(adata.obs['volume'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('cell volume (um^3)')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xscale('log')\n",
    "    ax.axvline(min_volume,color='red')\n",
    "    ax.axvline(max_volume,color='black')\n",
    "    ax.axhline(0.05,color='red')\n",
    "\n",
    "    # Total transcripts per cell\n",
    "    bins = np.logspace(0,3.5,20)\n",
    "    ax = axes[1]\n",
    "    ax.hist(adata.obs['total_counts'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('total transcripts')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xscale('log')\n",
    "    ax.axvline(min_counts,color='red')\n",
    "    ax.axhline(0.20,color='red')\n",
    "\n",
    "\n",
    "    # DAPI signal per cell\n",
    "    bins = np.logspace(2,8,20)\n",
    "    ax = axes[2]\n",
    "    ax.hist(adata.obs['DAPI_high_pass'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('DAPI')\n",
    "    ax.set_ylabel('fraction of cells')\n",
    "    ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "    ax.axvline(min_dapi,color='red')\n",
    "    ax.axhline(0.1,color='red')\n",
    "\n",
    "    # TB signal per cell\n",
    "    bins = np.logspace(2,6,20)\n",
    "    ax = axes[3]\n",
    "    ax.hist(adata.obs['Cellbound3_high_pass'], bins=bins,cumulative=True,density=True)\n",
    "    ax.set_xlabel('TB stain')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xscale('log')\n",
    "    ax.axhline(0.95,color='black')\n",
    "    ax.axvline(TB_threshold,color='black')\n",
    "\n",
    "    print('saving figure')\n",
    "    fig.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/'+experimentName+'region'+str(region)+'_basicQC.pdf')\n",
    "    print(\"size of adata object: \", adata.shape)\n",
    "    return adata\n",
    "\n",
    "def filter_h5ad(adata,min_volume=200, max_volume=5000, min_counts=20, min_dapi = 2000000):\n",
    "    #filter the object based on the thresholds above\n",
    "    cells = adata.shape[0]\n",
    "    adata = adata[(adata.obs['volume'] > min_volume) &\n",
    "         (adata.obs['volume'] < max_volume) &\n",
    "         (adata.obs['total_counts'] > min_counts) &\n",
    "         (adata.obs['DAPI_high_pass'] > min_dapi)].copy()\n",
    "    print('Filtering complete: ' + str(len(adata)) + ' cells remaining out of ' + str(cells) + ' original cells.')\n",
    "    return adata\n",
    "\n",
    "def show_spatial_plots(adata, clipx, experimentName, region,figsize = (10,10)):\n",
    "    #Show the section and add lines for any removal of damage\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sc.pl.spatial(adata, color='Cellbound3_high_pass', spot_size=50, ax=ax,color_map='OrRd',vmax=5000000)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axvline(clipx,color='red')\n",
    "    ax.axvline(clipx+1000,color='blue')\n",
    "\n",
    "    if experimentName == '202309251210_20230925-RitwicqA-TB_VMSC02401' and region=='1':\n",
    "        ax.axhline(6500,color='red')\n",
    "        ax.axhline(7500,color='blue')\n",
    "    sc.pl.spatial(adata, color='log_total_counts', spot_size=30, ax=ax)\n",
    "    \n",
    "def sc_preprocess(adata):\n",
    "    # Basic scanpy preprocessing\n",
    "    adata.X = adata.layers['counts'].copy()\n",
    "    sc.pp.normalize_total(adata,target_sum=100)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    #save normalized data\n",
    "    adata.layers['log_normalized'] = adata.X.copy()\n",
    "    print('log normalized')\n",
    "\n",
    "    #scale data\n",
    "    sc.pp.scale(adata)\n",
    "    adata.layers['scale_data'] = adata.X.copy()\n",
    "    print('scaled')\n",
    "\n",
    "    #run dimensional reduction\n",
    "    print('calculating pcs')\n",
    "    sc.pp.pca(adata)\n",
    "\n",
    "    print('calculating umap')\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    sc.tl.leiden(adata, resolution=0.5)\n",
    "\n",
    "    print('Scanpy processing complete.')\n",
    "    #check that counts remain\n",
    "    print(adata.layers['counts'][:1,:5])\n",
    "    return adata\n",
    "\n",
    "def tbcells_only_calculate_distance_to_tb(adata):\n",
    "    adata.obs['distance_to_tb'] = -100\n",
    "    #calculate euclidean distance from each of these cells to every other cell, find the minimum\n",
    "    tb_cells = adata.obs.index[adata.obs.TB_class_from_images=='High']\n",
    "    \n",
    "    #iterate over all tb cells\n",
    "    #find the location of the cell in space\n",
    "    #X_spatial is not an x-coordinate, it's a point\n",
    "    \n",
    "    for cell in tqdm(list(tb_cells)):\n",
    "        dist = []\n",
    "        cell_loc = np.round(list([adata.obs.center_x[cell],adata.obs.center_y[cell]]),decimals=2)\n",
    "    \n",
    "        #iterate over all TB+ cells and find the distance from each one to the cell in question\n",
    "        for tb_cell in tb_cells:\n",
    "            tb_cell_loc = np.round(list([adata.obs.center_x[tb_cell],adata.obs.center_y[tb_cell]]),decimals=2)\n",
    "            new_dist = np.round(math.dist(cell_loc,tb_cell_loc),decimals=2)\n",
    "            dist.append(new_dist)\n",
    "\n",
    "        #find the minimum distance to the 2nd tb+ cell\n",
    "        try:\n",
    "            min_dist = sorted(dist,reverse=False)[2]\n",
    "        except:\n",
    "            min_dist = 401\n",
    "            print('not enough cells to calculate min distance')\n",
    "        \n",
    "        #add this to the object\n",
    "        adata.obs.loc[cell,'distance_to_tb'] = min_dist\n",
    "        \n",
    "    #show any outliers in terms of cellbound 3 (tb) or distance to tb, print a graph\n",
    "    print(\"cells with TB signal above 5 million:\", adata[adata.obs.Cellbound3_high_pass>5e6].shape)\n",
    "    sc.pl.scatter(adata[adata.obs.TB_class_from_images=='High'],x='center_x',y='distance_to_tb',color='Cellbound3_high_pass')\n",
    "    \n",
    "    return adata\n",
    "\n",
    "#calculate euclidean distance from each of the tb+ cells to every other cell, find the minimum\n",
    "def calculate_distance_to_tb(adata):\n",
    "    if 'High' in set(adata.obs.TB_class_from_images):\n",
    "\n",
    "        adata.obs['distance_to_tb'] = -100\n",
    "\n",
    "\n",
    "        tb_cells = adata.obs.index[adata.obs.TB_class_from_images=='High']\n",
    "        count=1\n",
    "    #iterate over all cells\n",
    "        for cell in tqdm(list(adata.obs.index)):\n",
    "            dist = []\n",
    "    \n",
    "        #if the cell is TB+, distance = 0\n",
    "            if adata.obs.loc[cell,'TB_class_from_images']=='High':\n",
    "                adata.obs.loc[cell,'distance_to_tb'] = 0\n",
    "                continue\n",
    "        \n",
    "            cell_loc = np.round(list([adata.obs.center_x[cell],adata.obs.center_y[cell]]),decimals=2)\n",
    "    #if the cell is not TB+, calculate its distance from each TB+ cell\n",
    "    #iterate over all TB+ cells and find the distance from each one to the cell in question\n",
    "            for tb_cell in tb_cells:\n",
    "                tb_cell_loc = np.round(list([adata.obs.center_x[tb_cell],adata.obs.center_y[tb_cell]]),decimals=2)\n",
    "                new_dist = np.round(math.dist(cell_loc,tb_cell_loc),decimals=2)\n",
    "                dist.append(new_dist)\n",
    "\n",
    "    #find the minimum distance\n",
    "            min_dist = min(dist)\n",
    "    \n",
    "    #add this to the object\n",
    "            adata.obs.loc[cell,'distance_to_tb'] = min_dist\n",
    "    else:\n",
    "        adata.obs['distance_to_tb'] = 5000\n",
    "    return adata\n",
    "\n",
    "#run a permutation test comparing each transcript from within the binsize relative to a tb+ cell against all cells\n",
    "def permutation_test_for_tb_loc(adata,layer='log_normalized',binsize=100,perm_iterations=1000):\n",
    "\n",
    "    if isinstance(adata.layers[layer], scipy.sparse._csr.csr_matrix):\n",
    "        adata_df = pd.DataFrame.sparse.from_spmatrix(adata.layers[layer])\n",
    "        adata_df = adata_df.sparse.to_dense()\n",
    "    else:\n",
    "        adata_df = pd.DataFrame(adata.layers[layer])\n",
    "    adata_df.columns = adata.var.index\n",
    "    adata_df.index = adata.obs.index\n",
    "    adata_df['distance_real'] = adata.obs['distance_to_tb'].copy()\n",
    "    adata_df.columns = [i.replace('-','') for i in adata_df.columns]\n",
    "\n",
    "    adata_df['Bin'] = 'Null'\n",
    "\n",
    "    #for the first 4 bins, plot the distribution on top of this one in a different color\n",
    "    adata_df.loc[(adata_df.distance_real>=6*binsize) & (adata_df.distance_real<7*binsize),'Bin'] = 'Bin7'\n",
    "    adata_df.loc[(adata_df.distance_real>=3*binsize) & (adata_df.distance_real<4*binsize),'Bin'] = 'Bin4'\n",
    "    adata_df.loc[(adata_df.distance_real>=2*binsize) & (adata_df.distance_real<3*binsize),'Bin'] = 'Bin3'\n",
    "    adata_df.loc[(adata_df.distance_real>=binsize) & (adata_df.distance_real<2*binsize),'Bin'] = 'Bin2'\n",
    "    adata_df.loc[adata_df.distance_real<binsize,'Bin'] = 'Bin1'\n",
    "    adata_df.loc[adata_df.distance_real==0,'Bin'] = 'Bin0'\n",
    "    print(\"number of cells per bin: \",adata_df.Bin.value_counts())\n",
    "    adata_df = adata_df.sort_values('Bin',ascending=True)\n",
    "\n",
    "    #permutation test ~43 iterations/second\n",
    "    df_results = pd.DataFrame(columns=['sample_stat','average_stat','p_value'])\n",
    "    for transcript in tqdm(adata_df.columns[:140]):\n",
    "        ref_average = np.mean(adata_df.loc[~adata_df['Bin'].isin(['Bin1','Bin0']),transcript])\n",
    "        #print(ref_average)\n",
    "                              \n",
    "        sample_stat = np.mean(adata_df.loc[adata_df['Bin']=='Bin1',transcript]) - ref_average #calculate the difference in means between your bin1 distribution and the null distribution\n",
    "        stats = np.zeros(perm_iterations)\n",
    "        for k in range(perm_iterations):\n",
    "            labels = np.random.permutation((adata_df['Bin'] == 'Bin1').values) #randomly rearrange the bin labels so you get another sample in 'Bin1'\n",
    "            stats[k] = np.mean(adata_df[transcript][labels]) - ref_average #for each of 1000 iterations, calculate the difference between the random Bin1 Nos2 values and the null distribution\n",
    "    \n",
    "        if sample_stat>=0:\n",
    "            p_value = np.mean(stats > sample_stat)\n",
    "        if sample_stat<0:\n",
    "            p_value = np.mean(stats < sample_stat)\n",
    "    #save the stat and p-value per transcript\n",
    "        df_results.loc[transcript] = [sample_stat,np.mean(stats),p_value] \n",
    "\n",
    "    df_results = df_results.sort_values('p_value',ascending=True)\n",
    "    return adata_df, df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aff1b7-df90-483c-b017-d83c03bb3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations):\n",
    "    top_hits = df_results[(df_results.p_value<pval_threshold)].sort_values('sample_stat',ascending=False)\n",
    "    top_hits = list(top_hits[top_hits.sample_stat>stat_threshold].index)\n",
    "    top_hits = [i for i in top_hits if not i.startswith('Blank')]\n",
    "\n",
    "    bottom_hits =df_results[(df_results.p_value<pval_threshold) & (df_results.sample_stat< -stat_threshold)].index\n",
    "    bottom_hits = [i for i in bottom_hits if not i.startswith('Blank')]\n",
    "\n",
    "    #show violin or feature plots of these genes in the smartseq data\n",
    "   \n",
    "    if len(top_hits)>2:\n",
    "        sc.pl.heatmap(sc_data,top_hits,groupby='leiden',show_gene_labels=True)\n",
    "        #sc.pl.stacked_violin(sc_data,top_hits,groupby='leiden',rotation=90,title = 'Upregulated near TB')\n",
    "    if len(bottom_hits)>2:\n",
    "        sc.pl.heatmap(sc_data,bottom_hits,groupby='leiden',show_gene_labels=True)\n",
    "        #sc.pl.stacked_violin(sc_data,bottom_hits,groupby='leiden',rotation=90,title='Downregulated near TB')\n",
    "    \n",
    "    allprobes = [i for i in list(df_results.index) if not i.startswith('Blank')]\n",
    "\n",
    "    sc_data.var['UpNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(top_hits),'UpNearTB'] = True\n",
    "\n",
    "    sc_data.var['DownNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(bottom_hits),'DownNearTB'] = True\n",
    "\n",
    "    sc_data.var['UnchangedNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(allprobes),'UnchangedNearTB'] = True\n",
    "    sc_data.var.loc[sc_data.var['UpNearTB']==True,'UnchangedNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var['DownNearTB']==True,'UnchangedNearTB'] = False\n",
    "\n",
    "    print(\"up near TB: \", len(top_hits), \"\\ndown near TB:\", len(bottom_hits))\n",
    "\n",
    "    sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','UnchangedNearTB'],inplace=True)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    #sc.pl.violin(sc_data,['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'],groupby='leiden',rotation=90)\n",
    "    sc.pl.violin(sc_data,['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experimentName+'region'+str(region)+'ViolinPlot_UP_TB.pdf',ax=ax)\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experimentName+'region'+str(region)+experimentName+'region'+str(region)+'ViolinPlot_Down_TB.pdf',ax=ax)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_UnchangedNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experimentName+'region'+str(region)+'ViolinPlot_NOCHANGE_TB.pdf',ax=ax)\n",
    "\n",
    "    print(df_results.p_value[df_results.p_value>0].min())\n",
    "    df_results.loc[df_results.p_value==0,'p_value'] = 0.9/perm_iterations\n",
    "    df_results.to_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats'+experimentName+'_region'+str(region)+'.csv')\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(x = df_results.sample_stat, y=-np.log10(df_results.p_value))\n",
    "    plt.xlabel('difference in means, Bin1 - Null')\n",
    "    plt.ylabel('-log p value')\n",
    "\n",
    "    for i in range(df_results.shape[0]):\n",
    "        plt.text(x=df_results.sample_stat[i],y=-np.log10(df_results.p_value[i]),s=df_results.index[i], \n",
    "              fontdict=dict(color='black',size=10))\n",
    "    \n",
    "    plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/volcano'+experimentName+'_region'+str(region)+'.pdf')\n",
    "    return sc_data\n",
    "\n",
    "def plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax = 0):\n",
    "#run for each set of marker genes\n",
    "    for celltype in list(marker_dict.keys()):\n",
    "   \n",
    "        for transcript in marker_dict[celltype]:\n",
    "            if ymax==0:\n",
    "                ymax_new = max(adata_df[transcript])\n",
    "            else:\n",
    "                ymax_new=ymax\n",
    "    #if transcript not in ['Nos2','C1qa','C1qb','C1qc','Fcgr4','Lyve1']:\n",
    "        #continue\n",
    "  \n",
    "            fig,ax = plt.subplots(figsize=(5,3))\n",
    "            sns.histplot(data = adata_df,\n",
    "                 x=transcript, \n",
    "                 bins=10000, \n",
    "                 binrange=(0,ymax_new),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True,\n",
    "                color='Grey',\n",
    "                alpha=0.5)\n",
    "        \n",
    "    \n",
    "            sns.histplot(data = adata_df[adata_df.Bin!='Null'],\n",
    "                 x=transcript, \n",
    "                 hue='Bin', \n",
    "                 bins=10000, \n",
    "                 binrange=(0,ymax_new),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True, \n",
    "                 common_norm=False,\n",
    "                 palette = ['Black','Red','Orange','Green','Teal','Blue'])\n",
    "            ax.set_xlabel(celltype)\n",
    "            ax.set_ylabel('Cumulative Distribution')\n",
    "            ax.set_title(transcript)\n",
    "            ax.set_ylim(0,1)\n",
    "            fig.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/'+experimentName+'_region'+str(region)+'_'+transcript+'_histogram.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27cd7b-4f13-484d-8f6a-28ab67a3b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tb_pos_cells(adata,avg_signal_df, threshold, std_threshold,experimentName, region):\n",
    "    #add metrics to adata object\n",
    "    adata.obs.loc[avg_signal_df.index,'TB_std'] = avg_signal_df.std_signal\n",
    "    adata.obs.loc[avg_signal_df.index,'TB_mean'] = avg_signal_df.mean_signal\n",
    "    adata.obs.loc[avg_signal_df.index,'TB_topaverage'] = avg_signal_df.top_avg_signal\n",
    "\n",
    "    if experimentName=='202309251210_20230925-RitwicqA-TB_VMSC02401' and region=='2':\n",
    "        threshold = 250\n",
    "    \n",
    "    adata.obs['TB_class_from_images'] = 'High'\n",
    "    adata.obs.loc[adata.obs.TB_topaverage<=threshold,'TB_class_from_images'] = 'Low'\n",
    "    print('initial thresholding',adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "    adata.obs.loc[(adata.obs.TB_std<=std_threshold)&(adata.obs.TB_topaverage>threshold),'TB_class_from_images'] = 'Removed'\n",
    "    print('with sd cutoff',adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "\n",
    "    #run distance calculation\n",
    "    adata = tbcells_only_calculate_distance_to_tb(adata)\n",
    "\n",
    "    #print out initial counts, remove cells with high TB values and lone cells\n",
    "    adata.obs.loc[adata.obs.Cellbound3_high_pass>5e6,'TB_class_from_images']='Removed'\n",
    "    print('removed super high fluorescent cells', adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "    adata.obs.loc[adata.obs.distance_to_tb>400,'TB_class_from_images']='Removed' \n",
    "    print(\"removed lone cells\", adata.obs.TB_class_from_images.value_counts(sort=False))\n",
    "\n",
    "    if experimentName=='202305261458_TB-TEST3-MB_VMSC02401':\n",
    "        adata.obs.loc[adata.obs.center_x>4000,'TB_class_from_images'] = 'Removed'\n",
    "        print(adata.obs.TB_class_from_images.value_counts())\n",
    "    \n",
    "    adata.obs.TB_class_from_images.to_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Cell_annotation_csvs/'+experimentName+'region'+str(region)+'TB_binary.csv')\n",
    "    adata.obs.TB_class_from_images.value_counts()   \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    sc.pl.spatial(adata,color='TB_class_from_images',spot_size=30,palette=['red','lightgrey','grey'],ax=ax)\n",
    "\n",
    "    sc.pl.violin(adata,['center_x','center_y'],groupby='TB_class_from_images')\n",
    "    sc.pl.violin(adata,['TB_std','TB_mean'],groupby='TB_class_from_images')\n",
    "    sc.pl.violin(adata,['TB_topaverage','Cellbound3_high_pass'],groupby='TB_class_from_images')\n",
    "    sc.pl.scatter(adata,x='TB_topaverage',y='TB_std',color='TB_class_from_images',size=30)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(10,10))\n",
    "    ax.axvline(8000,color='black')\n",
    "    ax.axvline(9000,color='black') #1 mm\n",
    "    sc.pl.spatial(adata,spot_size=20,color = 'TB_class_from_images',palette=['red','lightgrey','grey'],ax=ax)\n",
    "    fig.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/'+experimentName+'region'+str(region)+'1mmscale_TBclass.pdf')       \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e3586-4356-45dd-98a9-2a8a823b9fb6",
   "metadata": {},
   "source": [
    "****1. Load in Shoshana's final smartseq object, remove neutrophils, and edit gene names:****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e5d82-8bc8-4f13-a2a6-8d321344a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data = sc.read_h5ad('/hpc/projects/data_lg/shoshana/Smartseq2nd/adataMNPNEW.h5ad')\n",
    "sc_data = sc_data[sc_data.obs.leiden!='Neutrophil'].copy()\n",
    "sc.pl.umap(sc_data,color = 'leiden')\n",
    "sc_data.var_names = [i.replace('-','') for i in sc_data.var_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36dcc6d-10f2-4e00-b3df-087f82479d7f",
   "metadata": {},
   "source": [
    "****2. Filter and QC the Vizgen h5ad file****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190b91c-b056-427b-97af-9122a98eec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a table\n",
    "experiment_df = pd.DataFrame(columns = ['experimentName','region','clipx'])\n",
    "experiment_df.loc[0] = ['202305231432_TB-CTRL1-MB_VMSC02401','0',0]\n",
    "experiment_df.loc[1] = ['202305231432_TB-CTRL1-MB_VMSC02401','1',0]\n",
    "experiment_df.loc[2] = ['202305231432_TB-CTRL1-MB_VMSC02401','2',0]\n",
    "experiment_df.loc[3] = ['202305251147_TB-CTRL2-MB_VMSC02401','0',0]\n",
    "experiment_df.loc[4] = ['202305251147_TB-CTRL2-MB_VMSC02401','1',0]\n",
    "experiment_df.loc[5] = ['202305261458_TB-TEST3-MB_VMSC02401','1',2000]\n",
    "experiment_df.loc[7] = ['202309251210_20230925-RitwicqA-TB_VMSC02401','1',7500]\n",
    "experiment_df.loc[8] = ['202309251210_20230925-RitwicqA-TB_VMSC02401','2',2500]\n",
    "experiment_df.loc[9] = ['202310091253_AmandaS-TB-02_VMSC02401','0',0]\n",
    "experiment_df.loc[10] = ['202310091253_AmandaS-TB-02_VMSC02401','1',0]\n",
    "experiment_df.loc[11] = ['202310091253_AmandaS-TB-02_VMSC02401','2',0]\n",
    "experiment_df.loc[12] = ['202310111428_RitwicqA-TB-4b_VMSC02401','1',0]\n",
    "experiment_df.loc[13] = ['202310111428_RitwicqA-TB-4b_VMSC02401','2',0]\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c837c-f46f-4afd-8d87-08accb3cd03d",
   "metadata": {},
   "source": [
    "Set all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217f710-733f-463b-984a-f3eb52daf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/hpc/projects/genomics/MERSCOPE/preprocessed_data'\n",
    "processedDataPath = '/hpc/projects/genomics/MERSCOPE/postprocessed_data/ProcessedCounts/'\n",
    "\n",
    "threshold = 300\n",
    "std_threshold = 150 \n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "binsize=100\n",
    "perm_iterations=10000\n",
    "pval_threshold = 0.001\n",
    "stat_threshold = 0.15\n",
    "\n",
    "marker_dict = {'High':['Nos2', 'H2Ab1', 'Irf1','C1qb'], 'Low':['Sparc','Jun','Lyve1'],'Neither':['Irf9','H2K1','Cxcr2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4810521d-803b-468a-a472-0b02e0d98343",
   "metadata": {},
   "source": [
    "## Run all the code on each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d20e1-4e74-4192-90af-f5466490b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for jloc in experiment_df.index:\n",
    "    experimentName = experiment_df.experimentName[jloc]\n",
    "    region = experiment_df.region[jloc]\n",
    "    clipx = experiment_df.clipx[jloc]\n",
    "    print(experimentName, region, clipx)\n",
    "\n",
    "    filenames = os.listdir(processedDataPath+experimentName)\n",
    "    filename = [i for i in filenames if i.endswith('.h5ad')][0]\n",
    "    \n",
    "    ## Process the vizgen adata file and filter out damaged tissue\n",
    "    adata = load_vizgen_h5ad(processedDataPath = processedDataPath,experimentName=experimentName, filename = filename, region=region,\n",
    "                    min_volume=200, max_volume=5000, min_counts=20, min_dapi = 2000000, TB_threshold = 700000)\n",
    "    adata = filter_h5ad(adata)\n",
    "    show_spatial_plots(adata,clipx, experimentName,region)\n",
    "\n",
    "    #remove any damage\n",
    "    adata = adata[adata.obs.center_x>clipx].copy()\n",
    "    if experimentName == '202309251210_20230925-RitwicqA-TB_VMSC02401' and region=='1':\n",
    "        adata = adata[adata.obs.center_y<6500].copy()\n",
    "    sc.pl.spatial(adata,spot_size=50)\n",
    "    adata = sc_preprocess(adata)\n",
    "    \n",
    "    ## Load in the image data and calculate metrics for each segment using the antibody information\n",
    "    \n",
    "    #collect data from images\n",
    "    df = load_tb_image_information(dataPath=dataPath,experimentName=experimentName,region=region)\n",
    "    #calculate average signal per cell for each metric\n",
    "    avg_signal_df = make_average_gdf(df,adata)\n",
    "    print(avg_signal_df.shape, adata.shape)\n",
    "\n",
    "    #Define TB positive cells\n",
    "    adata = assign_tb_pos_cells(adata,avg_signal_df, threshold,std_threshold,experimentName, region)\n",
    "\n",
    "    #normalize count data to polyA signal per cell\n",
    "    adata.layers['normalized_to_polyT'] = adata.layers['counts']/np.array(adata.obs.PolyT_high_pass).reshape(-1,1)*np.mean(adata.obs.PolyT_high_pass)\n",
    "    adata.layers['normalized_to_polyT'] = sparse.csr_matrix(adata.layers['normalized_to_polyT'])\n",
    "        \n",
    "    #skip these parts if there are not TB+ cells\n",
    "    if 'High' in set(adata.obs.TB_class_from_images):\n",
    "        \n",
    "        adata = calculate_distance_to_tb(adata)\n",
    "        adata.obs.distance_to_tb = adata.obs.distance_to_tb.astype('float')\n",
    "\n",
    "        adata_df, df_results = permutation_test_for_tb_loc(adata,layer=layer,binsize=binsize,perm_iterations=perm_iterations)\n",
    "        sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "\n",
    "        plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=50)\n",
    "    adata.write_h5ad('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Annotated_h5ad/'+experimentName+'_region'+str(region)+'_Annotated.h5ad')\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda02ff5-3e84-4a87-8b5c-26c1d0db1292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7e9a3c90-87f7-4776-a5e4-cd8bc1b620c3",
   "metadata": {},
   "source": [
    "#canonical markers:\n",
    "marker_dict = {}\n",
    "marker_dict['DC'] = ['Ccl22','Ccr2','Ccr7','Cd83','Cd86','Dpp4','Irf4','Irf8','Xcr1']\n",
    "marker_dict['AlvMac'] = ['Ccl6','Cd2','Clec4a2','Clec7a','Fabp4','Marco','Mrc1','Pparg']\n",
    "marker_dict['MatMoMac'] = ['C1qa','C1qb','C1qc','Fcgr1','Fcgr4']\n",
    "marker_dict['ImmMoMac'] = ['Apoe','Ccl9','Ccr2','Coro1a','Cx3cr1','Nr4a1','Plac8','Sell']\n",
    "marker_dict['Neutrophil'] = ['Csf3r','Cxcl2','Cxcr2','Il1r2','Mmp9']\n",
    "\n",
    "#these are the calculated markers\n",
    "marker_dict = {}\n",
    "marker_dict['DC'] =['Ccr7', 'Ccl22', 'Ly6d', 'Nr4a3', 'Xcr1', 'Dpp4', 'Irf4', 'Cd83']\n",
    "marker_dict['Neutrophil'] =['Cxcr2', 'Csf3r', 'Il1r2']\n",
    "marker_dict['AlvMac'] = ['Krt79', 'Plet1', 'Cd2', 'Car4', 'Mrc1', 'Marco', 'Tgfb2', 'Siglec1', 'Pparg']\n",
    "marker_dict['MatMoMac']=['Nos2', 'C1qc', 'C1qa', 'C1qb', 'Ms4a7', 'Sod2', 'Socs1', 'Cd40', 'Clec4e','Fcgr1' ]\n",
    "marker_dict['ImmMoMac']=['Nr4a1', 'Plac8', 'Cx3cr1', 'Sell', 'Spn', 'F13a1', 'Ccl9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e1708-de46-483d-a723-c113b4072880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show Dnase1l3 expression \n",
    "sc.pl.violin(adata,'Dnase1l3',groupby='TB_class_from_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1eb301-603d-47ce-b66b-252dcd16c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_tb = adata[adata.obs.Condition=='TB'].copy()\n",
    "print('Dnase1l3')\n",
    "for group in list(set(adata_tb.obs.grouped_distance_to_tb)):\n",
    "    far = adata_tb[adata_tb.obs.grouped_distance_to_tb==group,'Dnase1l3']\n",
    "    #calculate percent with positive Dnase1l3 counts\n",
    "    original = far.shape[0]\n",
    "    pos = far[far.layers['normalized_to_polyT']>1].shape[0]\n",
    "    print(group,pos/original*100)\n",
    " \n",
    "\n",
    "print('Nos2')\n",
    "for group in list(set(adata_tb.obs.grouped_distance_to_tb)):\n",
    "    far = adata_tb[adata_tb.obs.grouped_distance_to_tb==group,'Nos2']\n",
    "    #calculate percent with positive Dnase1l3 counts\n",
    "    original = far.shape[0]\n",
    "    pos = far[far.layers['normalized_to_polyT']>1].shape[0]\n",
    "    print(group,pos/original*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb4291-c75a-4d95-af17-4409a18255f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(sc_data,['Dnase1l3','Nos2'],groupby='leiden',rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0badc80-b7f0-4567-9b56-7bbc3142cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in final df_results and find consensus genes, plot top ones with a dot for each replicate, show consensus on violin plots for smartseq data\n",
    "#for cumulative distribution plots, show on total dataset\n",
    "\n",
    "#1. make a file with all the genes and all the data points\n",
    "\n",
    "\n",
    "folder = '/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/new_individual/tb/'\n",
    "df = pd.DataFrame(columns = ['gene','stat','p_value','experiment','region'])\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    experiment = file.split('_')[1]\n",
    "    region = file.split('_')[3].split('.')[0]\n",
    "    \n",
    "    stats = pd.read_csv(folder+file)\n",
    "    stats.columns = ['gene','stat','remove','p_value']\n",
    "    del stats['remove']\n",
    "    stats['experiment'] = experiment\n",
    "    stats['region'] = region\n",
    "\n",
    "    df = pd.concat([df, stats],ignore_index=True)\n",
    "\n",
    "#plot each gene using a swarmplot\n",
    "average_df = pd.DataFrame(columns=['average'])\n",
    "for gene in list(set(df.gene)):\n",
    "    mean = np.mean(df.loc[df.gene==gene].stat)\n",
    "    average_df.loc[gene] = mean\n",
    "    \n",
    "average_df = average_df.sort_values('average')\n",
    "gene_list = list(average_df.index)\n",
    "\n",
    "df['average_value'] = 0\n",
    "for gene in average_df.index:\n",
    "    df.loc[df.gene==gene,'average_value']=average_df.loc[gene,'average']\n",
    "df\n",
    "df = df.sort_values('average_value')\n",
    "df.p_value[df.p_value>0.0001] = 0.1\n",
    "df.p_value[df.p_value<0.0001] = 0.0001\n",
    "df.p_value.value_counts()\n",
    "\n",
    "df.to_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/statsAllTB_individualReplicates-excludingTB.csv')\n",
    "ax = sns.catplot(data=df.iloc[700:1125], \n",
    "                 x=\"stat\", \n",
    "                 y=\"gene\", \n",
    "                 hue=\"experiment\", \n",
    "                 #palette = ['red','orange','lightgrey'],\n",
    "                 kind=\"swarm\",\n",
    "                 aspect=1,\n",
    "                 height=10,\n",
    "                 row_order=gene_list)\n",
    "plt.savefig(\"/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/new/replicate_samplestat_experiment_last700samples-excludingtb.pdf\", format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.catplot(data=df, \n",
    "                 x=\"stat\", \n",
    "                 y=\"gene\", \n",
    "                 hue=\"experiment\", \n",
    "                 #palette = ['red','orange','lightgrey'],\n",
    "                 kind=\"swarm\",\n",
    "                 aspect=1,\n",
    "                 height=10,\n",
    "                 row_order=gene_list)\n",
    "\n",
    "plt.savefig(\"/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/new/replicate_samplestat_experiment-withoutTBcells.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c02939-a484-48cf-aa05-b5faf2eb7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f827b5-1841-437f-9291-98ef8ccb84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "df_new.loc[df_new.gene.str.startswith(\"Blank\"),'gene']='Blank'\n",
    "df_new = df_new.loc[~df_new.gene.isin(neither)]\n",
    "df_new\n",
    "\n",
    "ax = sns.catplot(data=df_new, \n",
    "                 x=\"stat\", \n",
    "                 y=\"gene\", \n",
    "                 hue=\"experiment\", \n",
    "                 #palette = ['red','orange','lightgrey'],\n",
    "                 kind=\"swarm\",\n",
    "                 aspect=1,\n",
    "                 height=10,\n",
    "                 row_order=gene_list)\n",
    "\n",
    "plt.savefig(\"/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/new/replicate_samplestat_experiment-withoutTBcells.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2452d7-c11b-4df6-9683-1a3ca3bd3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_df\n",
    "\n",
    "#from kruskal-wallis test (for upregulated genes) p<0.01 compared to all the blanks\n",
    "\n",
    "#clean up these markers\n",
    "low_markers = list(average_df.loc[average_df.average< -0.2].index)\n",
    "print(low_markers)\n",
    "high_markers = ['Ifng','Socs1','Cd40','C1qc','Atf3','Ifi30','Adam19','Cd2','Tnf','Cxcr4','C1qb','Junb','Socs3',\n",
    "                'Nfkb2','Csf3r','Il1b','Irf7','Ifngr1','Sparc','Clec7a','Irf5','Jak2','Tgfb1','H2D1','Lgals3',\n",
    "                'Coro1b','Spn','Clec4e','Lamp1','Sirpa','H2Eb1','Hmox1','Hif1a','Itgal','Coro1a','Stat1','Irf1','Ly6e','Nos2','H2Ab1',\n",
    "                'H2K1','Cd74']\n",
    "\n",
    "\n",
    "neither = [x for x in list(average_df.index) if x not in low_markers+high_markers]\n",
    "neither = [x for x in neither if not x.startswith('Blank')]\n",
    "\n",
    "heatmap_labels = {'Up':high_markers,'Down':low_markers}\n",
    "heatmap_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048cc5e-8255-4a4e-85d2-16bea7713b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a heatmap\n",
    "sc.pl.heatmap(sc_data,var_names = heatmap_labels, groupby='leiden',show_gene_labels=True,save = 'tbfinal_cleanmarkers.pdf')\n",
    "\n",
    "sc_data.var.UpNearTB=False\n",
    "sc_data.var.UnchangedNearTB=False\n",
    "sc_data.var.DownNearTB=False\n",
    "\n",
    "sc_data.var.loc[high_markers,'UpNearTB']=True\n",
    "sc_data.var.loc[low_markers,'DownNearTB']=True\n",
    "sc_data.var.loc[neither,'UnchangedNearTB']=True\n",
    "\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars = ['UpNearTB','DownNearTB','UnchangedNearTB'],percent_top=None,inplace=True,log1p=False)\n",
    "sc.pl.violin(sc_data,['pct_counts_UpNearTB','pct_counts_DownNearTB','pct_counts_UnchangedNearTB'],groupby='leiden',rotation=90,inner='quartile',save ='rip.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c497ee5-7cae-4de1-9576-f680d5950f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(sc_data,['pct_counts_UpNearTB','pct_counts_DownNearTB','pct_counts_UnchangedNearTB'],groupby='leiden',rotation=90,inner='quartile', save ='rip.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122290e-072c-4702-b586-9b78a806f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cd397-d68b-49e5-b6a3-2e6c870aa3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the h5ads and merge them into one object, re-normalize\n",
    "\n",
    "folder = '/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/'\n",
    "\n",
    "adata = concatenate_h5ad_folder(input_folder=folder+'Annotated_h5ad',\n",
    "                            output_folder=folder,\n",
    "                            name = 'concatenated_vizgen_h5ad',\n",
    "                            regex = ['date','slide','project','region'],\n",
    "                            regex_sep = '_',\n",
    "                            counts_threshold=0,\n",
    "                            genes_threshold=0,\n",
    "                            adata_file = 'None',\n",
    "                            save_frequency = 100)\n",
    "\n",
    "print(adata.obs['slide'].value_counts())\n",
    "\n",
    "adata.obs['Condition'] = 'Control'\n",
    "adata.obs.loc[~adata.obs.slide.isin(['TB-CTRL2-MB','TB-CTRL1-MB']),'Condition']='TB'\n",
    "print(adata.obs.groupby(['Condition','slide'])['fov'].count())\n",
    "\n",
    "adata.obs['genomics_personnel'] = 'Michael_Borja'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Amanda'),'genomics_personnel'] = 'Amanda_Seng'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Ritwicq'),'genomics_personnel'] = 'Ritwicq_Arjyal'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('20230925'),'genomics_personnel'] = 'Ritwicq_Arjyal'\n",
    "\n",
    "adata.obs['experiment_name'] = 'Control_1'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('20230925'),'experiment_name'] = 'TB_Mouse2_SectionA'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Ritwicq'),'experiment_name'] = 'TB_Mouse4_SectionB'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('Amanda'),'experiment_name'] = 'TB_Mouse4_SectionC'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('TB-TEST3'),'experiment_name'] = 'TB_MouseX_Test3'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('TB-CTRL2'),'experiment_name'] = 'Ctrl_MouseX_Exp2'\n",
    "adata.obs.loc[adata.obs.slide.str.startswith('TB-CTRL1'),'experiment_name'] = 'Ctrl_MouseX_Exp1'\n",
    "\n",
    "print(adata.obs.experiment_name.value_counts())\n",
    "\n",
    "adata.obs['full_sample'] = adata.obs.experiment_name.astype('str')+'_'+adata.obs.region.astype('str')\n",
    "adata.obs.full_sample.value_counts()\n",
    "\n",
    "adata.obs.PolyT_high_pass = adata.obs.PolyT_high_pass.astype('float')\n",
    "adata.layers['normalized_to_polyT'] = adata.layers['counts']/np.array(adata.obs.PolyT_high_pass).reshape(-1,1)*np.mean(adata.obs.PolyT_high_pass)\n",
    "adata.layers['normalized_to_polyT'] = sparse.csr_matrix(adata.layers['normalized_to_polyT'])\n",
    "       \n",
    "    \n",
    "adata.obs.distance_to_tb = adata.obs.distance_to_tb.astype('float')\n",
    "adata.obs['grouped_distance_to_tb'] = '1_far'\n",
    "adata.obs.loc[adata.obs.distance_to_tb<1000,'grouped_distance_to_tb'] = '2_within_1_mm'\n",
    "adata.obs.loc[adata.obs.distance_to_tb<100,'grouped_distance_to_tb'] = '3_within_100_um'\n",
    "adata.obs.loc[adata.obs.distance_to_tb==0,'grouped_distance_to_tb'] = '4_TBPositive'\n",
    "adata.obs.loc[adata.obs.distance_to_tb<-1,'grouped_distance_to_tb'] = '5_Unclear'\n",
    "\n",
    "adata.obs.grouped_distance_to_tb.value_counts()\n",
    "adata.var.index = [i.replace(\"-\",\"\") for i in adata.var.index]\n",
    "\n",
    "#save this object with all the columns\n",
    "\n",
    "adata.write_h5ad(folder+'Total_annotated_vizgen_TB_20231120.h5ad')\n",
    "\n",
    "adata_keep = adata.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3aac15-2166-42ef-92c6-69970b249fe1",
   "metadata": {},
   "source": [
    "Run code on the full adata object (TB only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4d845-9952-4974-b98b-ffd9479b99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentName='AllTB'\n",
    "region='All'\n",
    "perm_iterations=3000\n",
    "binsize=100\n",
    "\n",
    "pval_threshold = 0.001\n",
    "stat_threshold = 0.5\n",
    "\n",
    "marker_dict = {'up':['Cd74','Sparc'], #['Cd74','H2K1','Nos2','C1qb','Hmox1']\n",
    "              'down':['Lyve1','Dusp1'],\n",
    "              'neither':['Cx3cr1','Ms4a7']}\n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "\n",
    "adata_tb = adata[adata.obs.Condition=='TB'].copy()\n",
    "\n",
    "#adata_df, df_results = permutation_test_for_tb_loc(adata_tb,layer,binsize,perm_iterations)\n",
    "#sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188054d-c166-44cb-8a76-ae4ae5341125",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby(['experiment_name','Condition'])['fov'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87dd86-2d3a-4ca5-a2dc-ba35212853ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ba3a3-7d20-45f7-84b2-0fc17a1a4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict = {'up':['Cd74','H2K1','Nos2','C1qb','Hmox1'],\n",
    "              'down':['Lyve1','Dusp1'],\n",
    "              'neither':['Cx3cr1','Ms4a7','Apoe']}\n",
    "\n",
    "layer = 'normalized_to_polyT'\n",
    "\n",
    "#adata_tb = adata[adata.obs.Condition=='TB'].copy()\n",
    "\n",
    "#adata_df, df_results = permutation_test_for_tb_loc(adata_tb,layer,binsize,perm_iterations)\n",
    "#sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf0a4f-f9fb-4b53-bb60-2a6b5ac78b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data.var.index[sc_data.var.UpNearTB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f56cc-1ecc-4958-8b19-91e25e8e6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data.var.index[sc_data.var.DownNearTB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a62d73-11c1-4f2e-a442-d347490b0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'all_ymax_10'\n",
    "\n",
    "\n",
    "\n",
    "sc_data = plot_tb_altered_transcripts(sc_data,pval_threshold, stat_threshold, df_results,experimentName, region,perm_iterations)\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8cc8b-2f97-4149-acb9-cbc5e5e663ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168a900-e24c-4c12-81f0-9d97dae38721",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'all_ymax_10'\n",
    "marker_dict = {'up':['Cd74','H2K1','Nos2','C1qb','Hmox1'],\n",
    "              'down':['Lyve1','Dusp1'],\n",
    "              'neither':['Fabp4','Krt79']}\n",
    "plot_cumulative_dist(marker_dict,adata_df,experimentName,region,ymax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8eb68-5454-4721-8dd4-f54a6754922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from calculations with all samples together\n",
    "#note: top 30 genes from this method and the previous method are completely overlapping except for c1qb\n",
    "\n",
    "\n",
    "up_merged = sc_data.var.index[sc_data.var.UpNearTB]\n",
    "up_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c08a14-6d92-459e-b548-e9118f7d0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from calculations with each sample separate \n",
    "#top 40\n",
    "\n",
    "up_separate = average_df.sort_values('average',ascending=False)[:30].index\n",
    "up_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9450a8-2ad1-4669-bab9-3046af31e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in list(up_merged):\n",
    "    if gene in list(up_separate):\n",
    "        print(gene, \"is in both lists\")\n",
    "    else:\n",
    "        print(gene, \"is unique to the new calculation excluding TB+ cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463c338-a4dd-47e5-8671-62e606afab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data.var.index[sc_data.var.DownNearTB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10104cb2-fd13-4912-9a23-a67548c70822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run test once more (maybe with differential expression? on normalized to polyT data, comparing the within 200 um to within 1 mm and far categories)\n",
    "adata.X = adata.layers['normalized_to_polyT'].copy()\n",
    "sc.pp.log1p(adata)\n",
    "adata_test = adata[adata.obs.Condition=='TB'].copy()\n",
    "adata_test.obs.grouped_distance_to_tb = adata_test.obs.grouped_distance_to_tb.astype('object')\n",
    "sc.tl.rank_genes_groups(adata_test,\n",
    "                        groupby='grouped_distance_to_tb',\n",
    "                        groups=['3_within_100_um','4_TBPositive','1_far'],\n",
    "                        reference = '2_within_1_mm')\n",
    "\n",
    "df_ranked = sc.get.rank_genes_groups_df(adata_test, \n",
    "                                group='3_within_100_um',\n",
    "                                key='rank_genes_groups', \n",
    "                                pval_cutoff=None, \n",
    "                                log2fc_min=None, \n",
    "                                log2fc_max=None, \n",
    "                                gene_symbols=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39996cfd-3810-41a7-957b-94523a136d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups(adata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c1de6-7e2b-4e76-8126-0cb24ebd61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the top 10 genes and plot them across the adata categories\n",
    "\n",
    "sc.pl.stacked_violin(adata[adata.obs.Condition=='TB'],\n",
    "                     gene_list[100:140],\n",
    "                     groupby='grouped_distance_to_tb',\n",
    "                     layers='normalized_to_polyT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da6698-9bf2-486e-a214-6f129743807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot counts of the highest de genes\n",
    "stats = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats_Total_annotated_vizgen_TB_20231102_counts.csv',index_col=0)\n",
    "stats = stats.sort_values('sample_stat',ascending=False)\n",
    "stats[:30] #test statistic >1\n",
    "\n",
    "#try with all the genes\n",
    "genelist = list(stats.index)\n",
    "\n",
    "\n",
    "#grab cells that are within 100 um and in the TB object\n",
    "adata_keep.obs['distance_to_tb'] = adata_keep.obs['distance_to_tb'].astype('float')\n",
    "keep_cells = adata_keep[adata_keep.obs.Condition=='TB'].copy()\n",
    "keep_cells.var.index = [i.replace('-','') for i in keep_cells.var.index]\n",
    "\n",
    "#set up a dataframe to collect correlation coefficients\n",
    "correlation_frame = pd.DataFrame(index=genelist,columns=genelist)\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for i in range(0,len(genelist)):\n",
    "    gene_a = genelist[i]\n",
    "    gene_a_values = keep_cells[:,gene_a].layers['counts'].todense()\n",
    "    x = pd.DataFrame(gene_a_values)[0]\n",
    "    for j in range(0,len(genelist)):\n",
    "        gene_b = genelist[j]\n",
    "        gene_b_values = keep_cells[:,gene_b].layers['counts'].todense()\n",
    "        \n",
    "        y = pd.DataFrame(gene_b_values)[0]\n",
    "        pearson_coef, _ = np.round(pearsonr(x,y),decimals = 2)\n",
    "        correlation_frame.loc[gene_a,gene_b] = pearson_coef\n",
    "        if pearson_coef > 0.6:\n",
    "            print(\"Pearson correlation coefficient between\",gene_a,\"and\", gene_b, \":\", pearson_coef)\n",
    "            #sc.pl.scatter(keep_cells,x=gene_a, y = gene_b, color = 'distance_to_tb',layers='counts')\n",
    "\n",
    "    \n",
    "print(correlation_frame)\n",
    "\n",
    "#make a heatmap\n",
    "data = correlation_frame.astype('float')\n",
    "plt.imshow( data )\n",
    "plt.title( \"Correlation matrix between top 30 upregulated genes using raw counts\" )\n",
    "\n",
    " \n",
    "# Set tick labels\n",
    "plt.xticks(range(len(data.columns)),\\\n",
    "           data.columns, rotation=90)\n",
    "plt.yticks(range(len(data.columns)),\n",
    "           data.columns)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465c356-d6ee-4b3f-87ac-c5ce5a3672fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a heatmap\n",
    "data = correlation_frame.astype('float')\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow( data )\n",
    "plt.title( \"Correlation matrix between top 30 upregulated genes using raw counts\" )\n",
    "\n",
    " \n",
    "# Set tick labels\n",
    "plt.xticks(range(len(data.columns)),\\\n",
    "           data.columns, rotation=90)\n",
    "plt.yticks(range(len(data.columns)),\n",
    "           data.columns)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660299a8-8084-415c-b3fb-d3c0c63b34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#which genes are correlated? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d03a33-fe0a-4dfa-ad46-b36396a07167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot one gene at a time in the violin plots\n",
    "sc_data = sc.read_h5ad('/hpc/projects/data_lg/shoshana/Smartseq2nd/adataMNPNEW.h5ad')\n",
    "sc_data = sc_data[sc_data.obs.leiden!='Neutrophil'].copy()\n",
    "sc.pl.umap(sc_data,color = 'leiden')\n",
    "sc_data.var_names = [i.replace('-','') for i in sc_data.var_names]\n",
    "\n",
    "sc.pl.stacked_violin(sc_data,genelist[:30],groupby='leiden',swap_axes=True)\n",
    "sc.pl.stacked_violin(sc_data,genelist[123:140],groupby='leiden',swap_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c93621-ad88-4ad8-8812-57ba0af99921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot counts of the lowest de genes\n",
    "stats = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats_Total_annotated_vizgen_TB_20231102_counts.csv',index_col=0)\n",
    "stats = stats.sort_values('sample_stat',ascending=True)\n",
    "print(stats[:10]) #test statistic <= -0.3\n",
    "\n",
    "genelist = list(stats.index[:30])\n",
    "print(genelist)    \n",
    "\n",
    "for i in range(0,len(genelist)):\n",
    "    gene_a = genelist[i]\n",
    "    for j in range(i+1,len(genelist)):\n",
    "        gene_b = genelist[j]\n",
    "        sc.pl.scatter(keep_cells,x=gene_a, y = gene_b, color = 'distance_to_tb',layers='counts')\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa916d-5ed3-43bf-93f7-c06bd40f8e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e452c7b-5d2c-4b62-ac6c-503d67ed06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.scatter(keep_cells,x='Adam19',y='H2-K1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74b2db-abd7-471c-a534-d44767ec8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cells.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3976c5-38cd-45a5-ad8f-05e8065d2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating with raw counts to see if I get the same results\n",
    "#could also repeat by comparing the 100 um to some other distance\n",
    "\n",
    "#run the permutation test on A) all the controls, B) all the TB cells\n",
    "condition='TB'\n",
    "adata = adata_keep[adata_keep.obs.Condition==condition].copy()\n",
    "\n",
    "adata_df = pd.DataFrame.sparse.from_spmatrix(adata.layers['counts'])\n",
    "adata_df = adata_df.sparse.to_dense()\n",
    "adata_df.columns = adata.var.index\n",
    "adata_df.index = adata.obs.index\n",
    "adata_df['distance_real'] = adata.obs['distance_to_tb'].copy()\n",
    "adata_df.columns = [i.replace('-','') for i in adata_df.columns]\n",
    "\n",
    "adata_df['Bin'] = 'Null'\n",
    "binsize = 100\n",
    "\n",
    "#for the first 4 bins, plot the distribution on top of this one in a different color\n",
    "adata_df.distance_real = adata_df.distance_real.astype('float')\n",
    "adata_df.loc[(adata_df.distance_real>=6*binsize) & (adata_df.distance_real<7*binsize),'Bin'] = 'Bin7'\n",
    "adata_df.loc[(adata_df.distance_real>=3*binsize) & (adata_df.distance_real<4*binsize),'Bin'] = 'Bin4'\n",
    "adata_df.loc[(adata_df.distance_real>=2*binsize) & (adata_df.distance_real<3*binsize),'Bin'] = 'Bin3'\n",
    "adata_df.loc[(adata_df.distance_real>=binsize) & (adata_df.distance_real<2*binsize),'Bin'] = 'Bin2'\n",
    "adata_df.loc[adata_df.distance_real<binsize,'Bin'] = 'Bin1'\n",
    "print(\"number of cells per bin: \",adata_df.Bin.value_counts())\n",
    "adata_df = adata_df.sort_values('Bin',ascending=True)\n",
    "\n",
    "#permutation test ~43 iterations/second\n",
    "perm_iterations = 1000\n",
    "df_results = pd.DataFrame(columns=['sample_stat','average_stat','p_value'])\n",
    "for transcript in tqdm(adata_df.columns[:140]):\n",
    "    sample_stat = np.mean(adata_df.loc[adata_df['Bin']=='Bin1',transcript]) - np.mean(adata_df[transcript]) #calculate the difference in means between your bin1 distribution and the null distribution\n",
    "    stats = np.zeros(perm_iterations)\n",
    "    for k in range(perm_iterations):\n",
    "        labels = np.random.permutation((adata_df['Bin'] == 'Bin1').values) #randomly rearrange the bin labels so you get another sample in 'Bin1'\n",
    "        stats[k] = np.mean(adata_df[transcript][labels]) - np.mean(adata_df[transcript]) #for each of 1000 iterations, calculate the difference between the random Bin1 Nos2 values and the null distribution\n",
    "\n",
    "    if sample_stat>=0:\n",
    "        p_value = np.mean(stats > sample_stat)\n",
    "    if sample_stat<0:\n",
    "        p_value = np.mean(stats < sample_stat)\n",
    "    #save the stat and p-value per transcript\n",
    "    df_results.loc[transcript] = [sample_stat,np.mean(stats),p_value] \n",
    "\n",
    "df_results = df_results.sort_values('p_value',ascending=True)\n",
    "\n",
    "#increased close to TB\n",
    "top_hits = df_results[(df_results.p_value<0.001)].sort_values('sample_stat',ascending=False)\n",
    "top_hits = list(top_hits[top_hits.sample_stat>0].index)\n",
    "top_hits = [i for i in top_hits if not i.startswith('Blank')]\n",
    "\n",
    "bottom_hits =df_results[(df_results.p_value<0.001) & (df_results.sample_stat<0)].index\n",
    "bottom_hits = [i for i in bottom_hits if not i.startswith('Blank')]\n",
    "\n",
    "#show violin or feature plots of these genes in the smartseq data\n",
    "sc_data = sc.read_h5ad('/hpc/projects/data_lg/shoshana/Smartseq2nd/adataMNPNEW.h5ad')\n",
    "sc_data = sc_data[sc_data.obs.leiden!='Neutrophil'].copy()\n",
    "sc.pl.umap(sc_data,color = 'leiden')\n",
    "sc_data.var_names = [i.replace('-','') for i in sc_data.var_names]\n",
    "\n",
    "sc.pl.stacked_violin(sc_data,top_hits,groupby='leiden',rotation=90)\n",
    "\n",
    "allprobes = [i for i in list(df_results.index) if not i.startswith('Blank')]\n",
    "\n",
    "sc_data.var['UpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(top_hits),'UpNearTB'] = True\n",
    "\n",
    "sc_data.var['DownNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(bottom_hits),'DownNearTB'] = True\n",
    "\n",
    "sc_data.var['NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(allprobes),'NotUpNearTB'] = True\n",
    "sc_data.var.loc[sc_data.var['UpNearTB']==True,'NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var['DownNearTB']==True,'NotUpNearTB'] = False\n",
    "\n",
    "sc.pl.heatmap(sc_data,top_hits,groupby='leiden')\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','NotUpNearTB'],inplace=True)\n",
    "sc.pl.umap(sc_data,color = ['leiden'])\n",
    "sc.pl.umap(sc_data,color = ['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'])\n",
    "sc.pl.umap(sc_data,color = ['total_counts_NotUpNearTB','pct_counts_NotUpNearTB'])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "#sc.pl.violin(sc_data,['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'],groupby='leiden',rotation=90)\n",
    "sc.pl.violin(sc_data,['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_UP_TB.pdf',ax=ax)\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "sc.pl.violin(sc_data,['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_Down_TB.pdf',ax=ax)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "sc.pl.violin(sc_data,['pct_counts_NotUpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_NOTUP_TB.pdf',ax=ax)\n",
    "             \n",
    "print(df_results.p_value[df_results.p_value>0].min())\n",
    "df_results.loc[df_results.p_value==0,'p_value'] = 0.9/perm_iterations\n",
    "\n",
    "\n",
    "df_results.to_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats_'+condition+'rawcounts.csv')\n",
    "\n",
    "plt.scatter(x = df_results.sample_stat, y=-np.log10(df_results.p_value))\n",
    "plt.xlabel('difference in means, Bin1 - Null')\n",
    "plt.ylabel('-log p value')\n",
    "\n",
    "for i in range(df_results.shape[0]):\n",
    " plt.text(x=df_results.sample_stat[i],y=-np.log10(df_results.p_value[i]),s=df_results.index[i], \n",
    "          fontdict=dict(color='black',size=4))\n",
    "\n",
    "plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/volcano_'+condition+'rawcounts.pdf')\n",
    "\n",
    "print(df_results.sort_values('sample_stat',ascending=True)[:20])\n",
    "print(df_results.sort_values('sample_stat',ascending=False)[:20])   \n",
    "\n",
    "\n",
    "marker_dict = {'High':['Nos2', 'H2Ab1', 'Irf1','C1qb'], 'Low':['Sparc','Jun','Lyve1'],'Neither':['Irf9','H2K1','Cxcr2']}\n",
    "\n",
    "\n",
    "#run for each set of marker genes\n",
    "for celltype in list(marker_dict.keys()):\n",
    "   \n",
    "    for transcript in marker_dict[celltype]:\n",
    "    #if transcript not in ['Nos2','C1qa','C1qb','C1qc','Fcgr4','Lyve1']:\n",
    "        #continue\n",
    "\n",
    "        \n",
    "  \n",
    "        fig,ax = plt.subplots(figsize=(5,3))\n",
    "        sns.histplot(data = adata_df,\n",
    "                 x=transcript, \n",
    "                 bins=10000, \n",
    "                 binrange=(0,max(adata_df[transcript])),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True,\n",
    "                color='Grey',\n",
    "                alpha=0.5)\n",
    "        \n",
    "    \n",
    "        sns.histplot(data = adata_df[adata_df.Bin!='Null'],\n",
    "                 x=transcript, \n",
    "                 hue='Bin', \n",
    "                 bins=10000, \n",
    "                 binrange=(0,max(adata_df[transcript])),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True, \n",
    "                 common_norm=False,\n",
    "                palette = ['Red','Orange','Green','Teal','Blue'])\n",
    "        ax.set_xlabel(celltype)\n",
    "        ax.set_ylabel('Cumulative Distribution')\n",
    "        ax.set_title(transcript)\n",
    "        ax.set_ylim(0,1)\n",
    "        fig.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/'+condition+'_'+transcript+'rawcounts_histogram.pdf')        \n",
    "        \n",
    "print(\"Up: \",sc_data.var.UpNearTB.value_counts())\n",
    "print(\"Down: \", sc_data.var.DownNearTB.value_counts())\n",
    "print(\"Neither: \",sc_data.var.NotUpNearTB.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57706805-9277-4480-a3d2-02e42f9bb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "sc.pl.umap(sc_data,color='leiden',ax=ax,size=100,save='umap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df385a6-66b3-413c-9d51-8b4cd194e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directly compare the two \n",
    "adata = adata_keep.copy()\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c5cd2-3b57-47ed-84ab-f649d48f9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(adata.obs.full_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a318f1-8972-48c1-bbdf-457887673dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(adata.obs.groupby(['full_sample','TB_class_from_images'])['slide'].count())\n",
    "newdf = pd.DataFrame(index = list(set(adata.obs.full_sample)),columns = ['experiment','High','Low','Removed'])\n",
    "for i,j in df.index:\n",
    "    exp = i \n",
    "    tb_class = j\n",
    "    value = df.loc[i,j][0]\n",
    "    newdf.loc[i,j] = value\n",
    "    \n",
    "newdf.experiment = newdf.index.copy()\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d1bdd-4c10-48dd-9bf2-8e49017a1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_small = newdf[['experiment','High']]\n",
    "newdf_small = newdf_small.sort_values(\"High\")\n",
    "index_order = newdf_small.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92d3f7-d04a-472a-9cb8-3b51d444b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bar plot\n",
    "newdf_small.plot(x='experiment', kind='bar', stacked=True,\n",
    "        title='Number of cells classified as TB+ by section',color = 'red')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/TB_pos_cells_by_sample_bar.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f4da4-64fc-42d8-9c08-be7e559b8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['total'] = newdf.High+newdf.Low+newdf.Removed\n",
    "newdf_small = newdf[['experiment','total']]\n",
    "newdf_small = newdf_small.loc[index_order]\n",
    "newdf_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199835e-9289-43d4-8160-e17f76c0ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bar plot\n",
    "newdf_small.plot(x='experiment', kind='bar', stacked=True,\n",
    "        title='Total number of cells by section',color = 'grey')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/all_cells_by_sample_bar.pdf',format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01777d-f475-4335-a263-9506dd3414da",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_small = newdf[['experiment','High','total']]\n",
    "newdf_small['percent'] = newdf_small['High']*100/newdf_small['total']\n",
    "newdf_small = newdf_small[['experiment','percent']]\n",
    "newdf_small = newdf_small.loc[index_order]\n",
    "newdf_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30759012-dc03-4236-bf02-544f844e1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bar plot\n",
    "newdf_small.plot(x='experiment', kind='bar', stacked=True,\n",
    "        title='Total number of cells by section',color = 'grey')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/percent_tb_cells_by_sample_bar.pdf',format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd941e9-1896-48fe-bd0a-408dfd955b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in both data frames and compare the gene signatures\n",
    "ctrl_stats = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats_Control.csv',index_col=0)\n",
    "ctrl_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57081ec7-2781-478a-92da-f4b654381c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in both data frames and compare the gene signatures\n",
    "tb_stats = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats_TB.csv',index_col=0)\n",
    "tb_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8873e-7e18-4617-b56e-24c25a4bb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every gene, plot the tb sample_stat vs ctrl sample_stat\n",
    "#make a combined data frame\n",
    "all_stats = pd.DataFrame(index = tb_stats.index)\n",
    "all_stats['tb_sample_stat'] = tb_stats['sample_stat'].copy()\n",
    "all_stats['tb_pval'] = tb_stats['p_value'].copy()\n",
    "\n",
    "for i in all_stats.index:\n",
    "    all_stats.loc[i,'Ctrl_sample_stat'] = ctrl_stats.loc[i,'sample_stat']\n",
    "    all_stats.loc[i,'Ctrl_sample_pval'] = ctrl_stats.loc[i,'p_value']\n",
    "    \n",
    "all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0cffb-c849-4755-bf78-28815b29c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by tb_sample_stat and plot both tb and control stats\n",
    "all_stats = all_stats.sort_values('tb_sample_stat')\n",
    "all_stats['gene'] = all_stats.index.copy()\n",
    "\n",
    "#plot a volcano plot\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "ax.scatter(x = all_stats.tb_sample_stat, y=-np.log10(all_stats.tb_pval))\n",
    "ax.set_xlabel('difference in means, Bin1 - Null')\n",
    "ax.set_ylabel('-log p value')\n",
    "ax.set_title('TB volcano plot')\n",
    "\n",
    "for i in range(all_stats.shape[0]):\n",
    " ax.text(x=all_stats.tb_sample_stat[i],y=-np.log10(all_stats.tb_pval[i]),s=all_stats.gene[i], \n",
    "          color='black',size=8,rotation=30)\n",
    "\n",
    "print(all_stats.loc[abs(all_stats.tb_sample_stat)>0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f2211-2c74-49a0-a313-626d95624bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a volcano plot\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "ax.scatter(x = all_stats.Ctrl_sample_stat, y=-np.log10(all_stats.Ctrl_sample_pval))\n",
    "ax.set_xlabel('difference in means, Bin1 - Null')\n",
    "ax.set_ylabel('-log p value')\n",
    "ax.set_title('Ctrl volcano plot')\n",
    "\n",
    "for i in range(all_stats.shape[0]):\n",
    " ax.text(x=all_stats.Ctrl_sample_stat[i],y=-np.log10(all_stats.Ctrl_sample_pval[i]),s=all_stats.gene[i], \n",
    "          color='black',size=8,rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f417e-4b90-49b3-a96e-9e16c4a78d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a table comparing the genes that are significantly altered in the TB samples vs those significantly altered in the control samples\n",
    "tb_up = all_stats.gene[all_stats.tb_sample_stat>0.05]\n",
    "tb_down = all_stats.gene[all_stats.tb_sample_stat<-0.05]\n",
    "tb_neither = all_stats.gene[(all_stats.tb_sample_stat<0.05)&(all_stats.tb_sample_stat>-0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7175a-b45e-4f48-8962-8aac785d9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tb_up))\n",
    "x = all_stats.loc[tb_up,'Ctrl_sample_stat']>0.05\n",
    "all_stats.loc[x[x].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9436cd8-8bd1-41d1-9eb4-bf2acf86bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tb_down))\n",
    "x = all_stats.loc[tb_down,'Ctrl_sample_stat']<-0.05\n",
    "all_stats.loc[x[x].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea792e9-c3f9-4084-934c-4af3d98aaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_up = tb_up[~tb_up.isin(['C1qa','C1qb'])]\n",
    "tb_down = tb_down[~tb_down.isin(['Lyve1','Dusp1','Itga6','Scarf2','Ly6e','Atf4','Col4a1','H2D1','Car4','Lamp1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde96fc-079f-4003-b038-519a4d35b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-run the violin plots with these genes\n",
    "allprobes = [i for i in list(all_stats.index) if not i.startswith('Blank')]\n",
    "\n",
    "sc_data.var['UpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(tb_up),'UpNearTB'] = True\n",
    "\n",
    "sc_data.var['DownNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(tb_down),'DownNearTB'] = True\n",
    "\n",
    "sc_data.var['NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(allprobes),'NotUpNearTB'] = True\n",
    "sc_data.var.loc[sc_data.var['UpNearTB']==True,'NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var['DownNearTB']==True,'NotUpNearTB'] = False\n",
    "\n",
    "sc.pl.heatmap(sc_data,tb_up,groupby='leiden',show_gene_labels=True)\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','NotUpNearTB'],inplace=True)\n",
    "sc.pl.umap(sc_data,color = ['leiden'])\n",
    "sc.pl.umap(sc_data,color = ['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'])\n",
    "sc.pl.umap(sc_data,color = ['total_counts_NotUpNearTB','pct_counts_NotUpNearTB'])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "#sc.pl.violin(sc_data,['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'],groupby='leiden',rotation=90)\n",
    "sc.pl.violin(sc_data,['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_UP_limit01_strict_TB.pdf',ax=ax)\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "sc.pl.violin(sc_data,['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_Down_limit01_strict_TB.pdf',ax=ax)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_ylim(0,7)\n",
    "sc.pl.violin(sc_data,['pct_counts_NotUpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_NEITHER_limit01_strict_TB.pdf',ax=ax)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c2113-090a-4fd2-adf8-9a9bb79037ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e3c71-3a05-4137-8678-be850dfc1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#which genes are consistently up- or down-regulated across all of the TB experiments? \n",
    "i=0\n",
    "for file in os.listdir('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/individual/tb/'):\n",
    "    #print(file.split(\"_\",maxsplit=1)[1].split(\".\")[0])\n",
    "    stats = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/individual/tb/'+file,index_col=0)\n",
    "    upregulated = stats.loc[(stats.sample_stat>0.02)&(stats.p_value<0.01)].index\n",
    "    if i==0:\n",
    "        shared_upregulated=upregulated.copy()\n",
    "    else:\n",
    "        shared_upregulated = shared_upregulated[shared_upregulated.isin(upregulated)]\n",
    "shared_upregulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e7ffb-854a-462e-b032-62030ac0f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#which genes are consistently up- or down-regulated across all of the TB experiments? \n",
    "i=0\n",
    "for file in os.listdir('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/individual/tb/'):\n",
    "    #print(file.split(\"_\",maxsplit=1)[1].split(\".\")[0])\n",
    "    stats = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/individual/tb/'+file,index_col=0)\n",
    "    downregulated = stats.loc[(stats.sample_stat<-0.02)&(stats.p_value<0.01)].index\n",
    "    if i==0:\n",
    "        shared_downregulated=downregulated.copy()\n",
    "    else:\n",
    "        shared_downregulated = shared_downregulated[shared_downregulated.isin(downregulated)]\n",
    "shared_downregulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0b84a-cba5-4903-a545-bdb83d2e2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data.obs.leiden.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e0f9f-bc95-4ca8-87eb-fa6d3a95b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run violin plots with these genes\n",
    "#re-run the violin plots with these genes\n",
    "allprobes = [i for i in list(all_stats.index) if not i.startswith('Blank')]\n",
    "\n",
    "sc_data.var['UpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(shared_upregulated),'UpNearTB'] = True\n",
    "\n",
    "sc_data.var['DownNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(shared_downregulated),'DownNearTB'] = True\n",
    "\n",
    "sc_data.var['NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var.index.isin(allprobes),'NotUpNearTB'] = True\n",
    "sc_data.var.loc[sc_data.var['UpNearTB']==True,'NotUpNearTB'] = False\n",
    "sc_data.var.loc[sc_data.var['DownNearTB']==True,'NotUpNearTB'] = False\n",
    "\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','NotUpNearTB'],inplace=True)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(2,3))\n",
    "ax.set_ylim(0,6)\n",
    "#sc.pl.violin(sc_data,['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'],groupby='leiden',rotation=90)\n",
    "sc.pl.violin(sc_data[sc_data.obs.leiden.isin(['moDerived Macrophage','Immature_moDerived Macrophage'])],['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_UP_shared_TB.pdf',ax=ax)\n",
    "fig,ax = plt.subplots(figsize=(2,3))\n",
    "ax.set_ylim(0,6)\n",
    "sc.pl.violin(sc_data[sc_data.obs.leiden.isin(['moDerived Macrophage','Immature_moDerived Macrophage'])],['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_Down_shared_TB.pdf',ax=ax)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(2,3))\n",
    "ax.set_ylim(0,6)\n",
    "sc.pl.violin(sc_data[sc_data.obs.leiden.isin(['moDerived Macrophage','Immature_moDerived Macrophage'])],['pct_counts_NotUpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_NEITHER_shared_TB.pdf',ax=ax)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b6ada-b403-43bf-81f4-49f0f849fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sc.pl.violin(sc_data[sc_data.obs.leiden.isin(['moDerived Macrophage','Immature_moDerived Macrophage'])],['pct_counts_NotUpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = 'AllFiles_'+condition+'_ViolinPlot_NEITHER_shared_TB.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec7f67-6fa0-4e0e-b1d4-78dd2e9023f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.distance_to_tb = adata.obs.distance_to_tb.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df6db0-8e89-42de-a0bc-fc9f275b33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the TB-infected cells and directly compare them to their neighbors using pseudobulk\n",
    "adata = adata_keep[adata_keep.obs.Condition=='TB'].copy()\n",
    "adata.obs.distance_to_tb = adata.obs.distance_to_tb.astype('float')\n",
    "tb_cells = adata.obs.index[adata.obs.TB_class_from_images=='High']\n",
    "neighbors = adata.obs.index[(adata.obs.distance_to_tb<15)&(adata.obs.distance_to_tb>0)]\n",
    "\n",
    "print(len(tb_cells),len(neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60a988-bb9d-45e6-8009-a7765abe647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb9d30-c50c-4c8a-9d0d-48dc8147e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can grab the points directly from sc_data\n",
    "enriched_percentages = sc_data.obs.loc[sc_data.obs.leiden.isin(['moDerived Macrophage','Immature_moDerived Macrophage'])]\n",
    "enriched_percentages[['pct_counts_UpNearTB','pct_counts_DownNearTB','pct_counts_NotUpNearTB','leiden']]\n",
    "\n",
    "#run a t-test for each one comparing the leiden clusters to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0bfde-b0f3-4b19-9a29-8f0717f4ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grap the 95 percentiles from each one\n",
    "#up\n",
    "\n",
    "TBup_immature = enriched_percentages.pct_counts_UpNearTB.loc[enriched_percentages.leiden=='Immature_moDerived Macrophage']\n",
    "median = TBup_immature.median()\n",
    "upper_bound_95 = np.quantile(TBup_immature,.75)\n",
    "lower_bound_95 = np.quantile(TBup_immature,.25)\n",
    "print(\"Percentage of TB-induced transcripts in immature mo-derived Macrophages: 25th percentile, median, 75th percentile: \", lower_bound_95, median, upper_bound_95)\n",
    "\n",
    "TBup_mature = enriched_percentages.pct_counts_UpNearTB.loc[enriched_percentages.leiden=='moDerived Macrophage']\n",
    "median = TBup_mature.median()\n",
    "upper_bound_95 = np.quantile(TBup_mature,.75)\n",
    "lower_bound_95 = np.quantile(TBup_mature,.25)\n",
    "print(\"Percentage of TB-induced transcripts in mature mo-derived Macrophages: 25th percentile, median, 75th percentile: \", lower_bound_95, median, upper_bound_95)\n",
    "\n",
    "#down\n",
    "\n",
    "TBdown_immature = enriched_percentages.pct_counts_DownNearTB.loc[enriched_percentages.leiden=='Immature_moDerived Macrophage']\n",
    "median = TBdown_immature.median()\n",
    "upper_bound_95 = np.quantile(TBdown_immature,.75)\n",
    "lower_bound_95 = np.quantile(TBdown_immature,.25)\n",
    "print(\"Percentage of TB-suppressed transcripts in immature mo-derived Macrophages: 25th percentile, median, 75th percentile: \", lower_bound_95, median, upper_bound_95)\n",
    "\n",
    "TBdown_mature = enriched_percentages.pct_counts_DownNearTB.loc[enriched_percentages.leiden=='moDerived Macrophage']\n",
    "median = TBdown_mature.median()\n",
    "upper_bound_95 = np.quantile(TBdown_mature,.75)\n",
    "lower_bound_95 = np.quantile(TBdown_mature,.25)\n",
    "print(\"Percentage of TB-suppressed transcripts in mature mo-derived Macrophages: 25th percentile, median, 75th percentile: \", lower_bound_95, median, upper_bound_95)\n",
    "\n",
    "\n",
    "#neither\n",
    "\n",
    "TBneither_immature = enriched_percentages.pct_counts_NotUpNearTB.loc[enriched_percentages.leiden=='Immature_moDerived Macrophage']\n",
    "median = TBneither_immature.median()\n",
    "upper_bound_95 = np.quantile(TBneither_immature,.75)\n",
    "lower_bound_95 = np.quantile(TBneither_immature,.25)\n",
    "print(\"Percentage of TB-agnostic transcripts in immature mo-derived Macrophages: 25th percentile, median, 75th percentile: \", lower_bound_95, median, upper_bound_95)\n",
    "\n",
    "TBneither_mature = enriched_percentages.pct_counts_NotUpNearTB.loc[enriched_percentages.leiden=='moDerived Macrophage']\n",
    "median = TBneither_mature.median()\n",
    "upper_bound_95 = np.quantile(TBneither_mature,.75)\n",
    "lower_bound_95 = np.quantile(TBneither_mature,.25)\n",
    "print(\"Percentage of TB-agnostic transcripts in mature mo-derived Macrophages: 25th percentile, median, 75th percentile: \", lower_bound_95, median, upper_bound_95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1099e5-7641-4321-90b2-e1f2f3cee026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41ec37fe-e70b-4543-b981-eca71c97fd98",
   "metadata": {},
   "source": [
    "Run this part with all the cells together to see how it looks\n",
    "Might be worth running pseudobulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c1663-1df5-429b-911e-3434c959cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out the correct cells\n",
    "TB_cells = adata.obs.index[adata.obs.distance_to_tb==0]\n",
    "Near_cells = adata.obs.index[(adata.obs.distance_to_tb>0)&(adata.obs.distance_to_tb<12)]\n",
    "print(len(TB_cells),len(Near_cells))\n",
    "\n",
    "keep_cells = list(TB_cells)+list(Near_cells)\n",
    "adata_sub = adata[adata.obs.index.isin(keep_cells)].copy()\n",
    "adata_sub.obs.loc[TB_cells,'distance_group'] = 'TB_infected'\n",
    "adata_sub.obs.loc[Near_cells,'distance_group'] = 'uninfected'\n",
    "adata_sub.obs.distance_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1f1f6-a4a4-4ae1-b15b-e9dcde8dc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run DE in mast\n",
    "column = 'distance_group'\n",
    "layer = 'log_normalized'\n",
    "out_folder = '/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/exported_formast/'\n",
    "#1. save files for opening in R\n",
    "sio.mmwrite(out_folder +\"sparse_matrix.mtx\",adata_sub.layers[layer])\n",
    "adata_sub.obs[column].astype('str').to_csv(out_folder+'obs.csv')\n",
    "pd.DataFrame(adata_sub.var.index).to_csv(out_folder+'var.csv',index=0)\n",
    "\n",
    "#conda activate popv\n",
    "#Rscript /hpc/projects/data.science/leah.dorman/notebooks/Spatial/Vizgen/mast.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee2fe5-52d6-40b6-adf0-46186c5b862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mast tutorial (without seurat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fb830-f0e1-4ece-b83f-88d73c1de9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from mast\n",
    "rankedgenes = pd.read_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/exported_formast/distance_group_TB_infected_vs_uninfected_MAST.csv')\n",
    "rankedgenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e45be6-b73d-4913-859e-21844af028dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#volcano\n",
    "#change this plot by assigning zeros to a number smaller than the smallest p value possible\n",
    "plt.scatter(x = rankedgenes.coef, y=-np.log10(rankedgenes.fdr))\n",
    "plt.xlabel('log fold change, TB infected vs neighbors')\n",
    "plt.ylabel('-log p value')\n",
    "plt.xlim(-0.6,0.6)\n",
    "plt.axvline(0, color='black')\n",
    "#which labels to plot\n",
    "threshold = 0.1\n",
    "for i in range(rankedgenes.shape[0]):\n",
    "    if abs(rankedgenes.coef[i])>threshold:\n",
    "        plt.text(x=rankedgenes.coef[i],y=-np.log10(rankedgenes.fdr[i]),s=rankedgenes.primerid[i], fontdict=dict(color='black',size=8))\n",
    "\n",
    "plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/TBinfected_vs_neighbors_volcano.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64aa54-689b-4129-8ea9-c56ba0f548a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do these genes compare to the single cell experiment? \n",
    "up_in_tb = rankedgenes.primerid.loc[(rankedgenes.fdr<0.01)&(rankedgenes.coef>0.1)]\n",
    "down_in_tb = rankedgenes.primerid.loc[(rankedgenes.fdr<0.01)&(rankedgenes.coef<-0.1)]\n",
    "down_in_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbda327-340f-4db4-9445-f24127bef27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data.var['UpINTB'] = False\n",
    "sc_data.var['DownINTB'] = False\n",
    "sc_data.var.UpINTB.loc[sc_data.var.index.isin(up_in_tb)]=True\n",
    "sc_data.var.DownINTB.loc[sc_data.var.index.isin(down_in_tb)]=True\n",
    "\n",
    "#calculate qc metrics\n",
    "sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpINTB','DownINTB'],inplace=True)\n",
    "\n",
    "sc.pl.violin(sc_data,['pct_counts_UpINTB','pct_counts_DownINTB'],groupby='leiden',rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3130697-1b16-49b7-a2ae-5a7b82141c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think for this analysis to work you actually have to pull out the macrophages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c6478-7c90-4bc0-82af-32b9e64c765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #do most transcripts scale with cell size? \n",
    "# #plot total counts vs transcript counts\n",
    "# adata.X = adata.layers['counts'].copy()\n",
    "# for transcript in adata.var.index[:20]:\n",
    "#     sc.pl.scatter(adata,x='total_counts',y=transcript,color='experiment_name')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2bbd6-b9a8-4cfe-a3fa-90c8db041a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#could try loading in each each experiment from the folder, running the permutation test on raw counts, finding the merged;\n",
    "folder = '/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Annotated_h5ad/'\n",
    "for file in os.listdir(folder):\n",
    "    adata = sc.read_h5ad(folder+file)\n",
    "    experiment = file.split(\".\")[0]\n",
    "    print(experiment)\n",
    "    #repeating with raw counts to see if I get the same results\n",
    "#could also repeat by comparing the 100 um to some other distance\n",
    "\n",
    "#run the permutation test on A) all the controls, B) all the TB cells\n",
    "# condition='TB'\n",
    "# adata = adata_keep[adata_keep.obs.Condition==condition].copy()\n",
    "    layer = 'counts'\n",
    "\n",
    "    adata_df = pd.DataFrame.sparse.from_spmatrix(adata.layers[layer])\n",
    "    adata_df = adata_df.sparse.to_dense()\n",
    "    adata_df.columns = adata.var.index\n",
    "    adata_df.index = adata.obs.index\n",
    "    adata_df['distance_real'] = adata.obs['distance_to_tb'].copy()\n",
    "    adata_df.columns = [i.replace('-','') for i in adata_df.columns]\n",
    "\n",
    "    adata_df['Bin'] = 'Null'\n",
    "    binsize = 100\n",
    "\n",
    "#for the first 4 bins, plot the distribution on top of this one in a different color\n",
    "    adata_df.distance_real = adata_df.distance_real.astype('float')\n",
    "    adata_df.loc[(adata_df.distance_real>=6*binsize) & (adata_df.distance_real<7*binsize),'Bin'] = 'Bin7'\n",
    "    adata_df.loc[(adata_df.distance_real>=3*binsize) & (adata_df.distance_real<4*binsize),'Bin'] = 'Bin4'\n",
    "    adata_df.loc[(adata_df.distance_real>=2*binsize) & (adata_df.distance_real<3*binsize),'Bin'] = 'Bin3'\n",
    "    adata_df.loc[(adata_df.distance_real>=binsize) & (adata_df.distance_real<2*binsize),'Bin'] = 'Bin2'\n",
    "    adata_df.loc[adata_df.distance_real<binsize,'Bin'] = 'Bin1'\n",
    "    print(\"number of cells per bin: \",adata_df.Bin.value_counts())\n",
    "    adata_df = adata_df.sort_values('Bin',ascending=True)\n",
    "\n",
    "#permutation test ~43 iterations/second\n",
    "    perm_iterations = 1000\n",
    "    df_results = pd.DataFrame(columns=['sample_stat','average_stat','p_value'])\n",
    "    for transcript in tqdm(adata_df.columns[:140]):\n",
    "        sample_stat = np.mean(adata_df.loc[adata_df['Bin']=='Bin1',transcript]) - np.mean(adata_df[transcript]) #calculate the difference in means between your bin1 distribution and the null distribution\n",
    "        stats = np.zeros(perm_iterations)\n",
    "        for k in range(perm_iterations):\n",
    "            labels = np.random.permutation((adata_df['Bin'] == 'Bin1').values) #randomly rearrange the bin labels so you get another sample in 'Bin1'\n",
    "            stats[k] = np.mean(adata_df[transcript][labels]) - np.mean(adata_df[transcript]) #for each of 1000 iterations, calculate the difference between the random Bin1 Nos2 values and the null distribution\n",
    "    \n",
    "        if sample_stat>=0:\n",
    "            p_value = np.mean(stats > sample_stat)\n",
    "        if sample_stat<0:\n",
    "            p_value = np.mean(stats < sample_stat)\n",
    "    #save the stat and p-value per transcript\n",
    "        df_results.loc[transcript] = [sample_stat,np.mean(stats),p_value] \n",
    "\n",
    "    df_results = df_results.sort_values('p_value',ascending=True)\n",
    "\n",
    "#increased close to TB\n",
    "    top_hits = df_results[(df_results.p_value<0.001)].sort_values('sample_stat',ascending=False)\n",
    "    top_hits = list(top_hits[top_hits.sample_stat>0.1].index)\n",
    "    top_hits = [i for i in top_hits if not i.startswith('Blank')]\n",
    "\n",
    "    bottom_hits =df_results[(df_results.p_value<0.001) & (df_results.sample_stat<-0.1)].index\n",
    "    bottom_hits = [i for i in bottom_hits if not i.startswith('Blank')]\n",
    "\n",
    "#show violin or feature plots of these genes in the smartseq data\n",
    "    sc_data = sc.read_h5ad('/hpc/projects/data_lg/shoshana/Smartseq2nd/adataMNPNEW.h5ad')\n",
    "    sc_data = sc_data[sc_data.obs.leiden!='Neutrophil'].copy()\n",
    "    #sc.pl.umap(sc_data,color = 'leiden')\n",
    "    sc_data.var_names = [i.replace('-','') for i in sc_data.var_names]\n",
    "\n",
    "    try:\n",
    "        sc.pl.stacked_violin(sc_data,top_hits,groupby='leiden',rotation=90)\n",
    "    except:\n",
    "        print('too little data for stacked violin')\n",
    "    allprobes = [i for i in list(df_results.index) if not i.startswith('Blank')]\n",
    "\n",
    "    sc_data.var['UpNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(top_hits),'UpNearTB'] = True\n",
    "\n",
    "    sc_data.var['DownNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(bottom_hits),'DownNearTB'] = True\n",
    "\n",
    "    sc_data.var['NotUpNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var.index.isin(allprobes),'NotUpNearTB'] = True\n",
    "    sc_data.var.loc[sc_data.var['UpNearTB']==True,'NotUpNearTB'] = False\n",
    "    sc_data.var.loc[sc_data.var['DownNearTB']==True,'NotUpNearTB'] = False\n",
    "\n",
    "    try:\n",
    "        sc.pl.heatmap(sc_data,top_hits,groupby='leiden')\n",
    "    except:\n",
    "        print('too little data')\n",
    "    sc.pp.calculate_qc_metrics(sc_data,qc_vars=['UpNearTB','DownNearTB','NotUpNearTB'],inplace=True)\n",
    "    #sc.pl.umap(sc_data,color = ['leiden'])\n",
    "    #sc.pl.umap(sc_data,color = ['total_counts_UpNearTB','pct_counts_UpNearTB','total_counts_DownNearTB','pct_counts_DownNearTB'])\n",
    "    #sc.pl.umap(sc_data,color = ['total_counts_NotUpNearTB','pct_counts_NotUpNearTB'])\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_UpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experiment+'_'+layer+'_ViolinPlot_UP_TB.pdf',ax=ax)\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_DownNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experiment+'_'+layer+'_ViolinPlot_Down_TB.pdf',ax=ax)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    ax.set_ylim(0,7)\n",
    "    sc.pl.violin(sc_data,['pct_counts_NotUpNearTB'],groupby='leiden',rotation=90,inner='quartile',save = experiment+'_'+layer+'_ViolinPlot_NOTUP_TB.pdf',ax=ax)\n",
    "             \n",
    "    print(df_results.p_value[df_results.p_value>0].min())\n",
    "    df_results.loc[df_results.p_value==0,'p_value'] = 0.9/perm_iterations\n",
    "\n",
    "\n",
    "    df_results.to_csv('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Stats/stats_'+experiment+'_'+layer+'.csv')\n",
    "\n",
    "    plt.scatter(x = df_results.sample_stat, y=-np.log10(df_results.p_value))\n",
    "    plt.xlabel('difference in means, Bin1 - Null')\n",
    "    plt.ylabel('-log p value')\n",
    "\n",
    "    for i in range(df_results.shape[0]):\n",
    "     plt.text(x=df_results.sample_stat[i],y=-np.log10(df_results.p_value[i]),s=df_results.index[i], \n",
    "          fontdict=dict(color='black',size=4))\n",
    "\n",
    "    plt.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/volcano_'+experiment+'_'+layer+'_'+'.pdf')\n",
    "\n",
    "    print(df_results.sort_values('sample_stat',ascending=True)[:20])\n",
    "    print(df_results.sort_values('sample_stat',ascending=False)[:20])   \n",
    "\n",
    "\n",
    "    marker_dict = {'High':['Nos2', 'Cd74', 'Irf1','C1qb'], 'Low':['Sparc','Jun','Lyve1','Ly6e'],'Neither':['Irf9','H2K1','Cxcr2']}\n",
    "\n",
    "\n",
    "    #run for each set of marker genes\n",
    "    for celltype in list(marker_dict.keys()):\n",
    "   \n",
    "        for transcript in marker_dict[celltype]:\n",
    "    #if transcript not in ['Nos2','C1qa','C1qb','C1qc','Fcgr4','Lyve1']:\n",
    "        #continue\n",
    "\n",
    "        \n",
    "  \n",
    "            fig,ax = plt.subplots(figsize=(5,3))\n",
    "            sns.histplot(data = adata_df,\n",
    "                 x=transcript, \n",
    "                 bins=10000, \n",
    "                 binrange=(0,max(adata_df[transcript])),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True,\n",
    "                color='Grey',\n",
    "                alpha=0.5)\n",
    "        \n",
    "    \n",
    "            sns.histplot(data = adata_df[adata_df.Bin!='Null'],\n",
    "                 x=transcript, \n",
    "                 hue='Bin', \n",
    "                 bins=10000, \n",
    "                 binrange=(0,max(adata_df[transcript])),\n",
    "                 stat=\"density\",\n",
    "                 element=\"step\", \n",
    "                 fill=False, \n",
    "                 cumulative=True, \n",
    "                 common_norm=False,\n",
    "                palette = ['Red','Orange','Green','Teal','Blue'])\n",
    "            ax.set_xlabel(celltype)\n",
    "            ax.set_ylabel('Cumulative Distribution')\n",
    "            ax.set_title(transcript)\n",
    "            ax.set_ylim(0,1)\n",
    "            fig.savefig('/hpc/projects/data.science/leah.dorman/Spatial/Vizgen/Shoshana/Figures/'+experiment+'_'+transcript+'_'+layer+'_histogram.pdf')        \n",
    "        \n",
    "    print(experiment, \"Up: \",sc_data.var.UpNearTB.value_counts())\n",
    "    print(\"Down: \", sc_data.var.DownNearTB.value_counts())\n",
    "    print(\"Neither: \",sc_data.var.NotUpNearTB.value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f195703-a093-41ab-84b9-ddc15ce727dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-popv]",
   "language": "python",
   "name": "conda-env-.conda-popv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
